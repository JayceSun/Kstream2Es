2018-02-08 16:24:00,800 [pool-3-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.util.PropertyReaderUtil] - 配置文件被修改
2018-02-08 16:24:00,930 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.util.ESTools] - ESTools开始创建client
2018-02-08 16:24:00,971 [pool-1-thread-1] INFO  [org.elasticsearch.plugins] - [Raman] modules [], plugins [], sites []
2018-02-08 16:24:01,005 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Raman] creating thread_pool [force_merge], type [fixed], size [1], queue_size [null]
2018-02-08 16:24:01,012 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Raman] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
2018-02-08 16:24:01,038 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Raman] creating thread_pool [fetch_shard_started], type [scaling], min [1], size [8], keep_alive [5m]
2018-02-08 16:24:01,085 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Raman] creating thread_pool [listener], type [fixed], size [2], queue_size [null]
2018-02-08 16:24:01,086 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Raman] creating thread_pool [index], type [fixed], size [4], queue_size [200]
2018-02-08 16:24:01,086 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Raman] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
2018-02-08 16:24:01,086 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Raman] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
2018-02-08 16:24:01,086 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Raman] creating thread_pool [generic], type [cached], keep_alive [30s]
2018-02-08 16:24:01,087 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Raman] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
2018-02-08 16:24:01,087 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Raman] creating thread_pool [search], type [fixed], size [7], queue_size [1k]
2018-02-08 16:24:01,088 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Raman] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
2018-02-08 16:24:01,089 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Raman] creating thread_pool [fetch_shard_store], type [scaling], min [1], size [8], keep_alive [5m]
2018-02-08 16:24:01,089 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Raman] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
2018-02-08 16:24:01,089 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Raman] creating thread_pool [get], type [fixed], size [4], queue_size [1k]
2018-02-08 16:24:01,089 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Raman] creating thread_pool [bulk], type [fixed], size [4], queue_size [50]
2018-02-08 16:24:01,089 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Raman] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
2018-02-08 16:24:01,783 [pool-1-thread-1] DEBUG [org.elasticsearch.common.network] - configuration:

lo
        Software Loopback Interface 1
        inet 127.0.0.1 netmask:255.0.0.0 broadcast:127.255.255.255 scope:host
        inet6 ::1 prefixlen:128 scope:host
        UP MULTICAST LOOPBACK mtu:-1 index:1

eth0
        Realtek PCIe GBE Family Controller
        inet 172.16.73.125 netmask:255.255.255.0 broadcast:172.16.73.255 scope:site
        inet6 fe80::52b:2670:705d:338e prefixlen:64 scope:link
        hardware 1C:1B:0D:B1:E1:B3
        UP MULTICAST mtu:1500 index:2

eth1
        Microsoft Kernel Debug Network Adapter
        MULTICAST mtu:-1 index:3

eth2
        Realtek PCIe GBE Family Controller #2
        MULTICAST mtu:-1 index:4

eth3
        Realtek PCIe GBE Family Controller-WFP Native MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:5

eth4
        Realtek PCIe GBE Family Controller-iNode LightWeight Filter-0000
        MULTICAST mtu:-1 index:6

eth5
        Realtek PCIe GBE Family Controller-QoS Packet Scheduler-0000
        MULTICAST mtu:-1 index:7

eth6
        Realtek PCIe GBE Family Controller-WFP 802.3 MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:8

net0
        WAN Miniport (SSTP)
        MULTICAST mtu:-1 index:9

net1
        WAN Miniport (IKEv2)
        MULTICAST mtu:-1 index:10

net2
        WAN Miniport (L2TP)
        MULTICAST mtu:-1 index:11

net3
        WAN Miniport (PPTP)
        MULTICAST mtu:-1 index:12

ppp0
        WAN Miniport (PPPOE)
        MULTICAST mtu:-1 index:13

eth7
        WAN Miniport (IP)
        MULTICAST mtu:-1 index:14

eth8
        WAN Miniport (IP)-WFP Native MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:15

eth9
        WAN Miniport (IP)-iNode LightWeight Filter-0000
        MULTICAST mtu:-1 index:16

eth10
        WAN Miniport (IP)-QoS Packet Scheduler-0000
        MULTICAST mtu:-1 index:17

eth11
        WAN Miniport (IPv6)
        MULTICAST mtu:-1 index:18

eth12
        WAN Miniport (IPv6)-WFP Native MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:19

eth13
        WAN Miniport (IPv6)-iNode LightWeight Filter-0000
        MULTICAST mtu:-1 index:20

eth14
        WAN Miniport (IPv6)-QoS Packet Scheduler-0000
        MULTICAST mtu:-1 index:21

eth15
        WAN Miniport (Network Monitor)
        MULTICAST mtu:-1 index:22

eth16
        WAN Miniport (Network Monitor)-WFP Native MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:23

eth17
        WAN Miniport (Network Monitor)-iNode LightWeight Filter-0000
        MULTICAST mtu:-1 index:24

eth18
        WAN Miniport (Network Monitor)-QoS Packet Scheduler-0000
        MULTICAST mtu:-1 index:25

net4
        Teredo Tunneling Pseudo-Interface
        inet6 2001:0:9d38:6ab8:28ec:1162:53ef:b682 prefixlen:0
        inet6 fe80::28ec:1162:53ef:b682 prefixlen:32 scope:link
        hardware 00:00:00:00:00:00:00:E0
        UP POINTOPOINT mtu:1280 index:26

2018-02-08 16:24:01,815 [pool-1-thread-1] DEBUG [org.elasticsearch.common.netty] - using gathering [true]
2018-02-08 16:24:01,953 [pool-1-thread-1] DEBUG [org.elasticsearch.client.transport] - [Raman] node_sampler_interval[5s]
2018-02-08 16:24:01,972 [pool-1-thread-1] DEBUG [org.elasticsearch.netty.channel.socket.nio.SelectorUtil] - Using select timeout of 500
2018-02-08 16:24:01,972 [pool-1-thread-1] DEBUG [org.elasticsearch.netty.channel.socket.nio.SelectorUtil] - Epoll-bug workaround enabled = false
2018-02-08 16:24:02,016 [pool-1-thread-1] DEBUG [org.elasticsearch.client.transport] - [Raman] adding address [{#transport#-1}{172.16.23.13}{172.16.23.13:9303}]
2018-02-08 16:24:02,148 [elasticsearch[Raman][management][T#1]] DEBUG [org.elasticsearch.transport.netty] - [Raman] connected to node [{#transport#-1}{172.16.23.13}{172.16.23.13:9303}]
2018-02-08 16:24:02,512 [pool-1-thread-1] DEBUG [org.elasticsearch.transport.netty] - [Raman] connected to node [{node02}{phQmsLojTs2ghLCQ4Qd9mg}{172.16.23.15}{172.16.23.15:9303}{max_local_storage_nodes=2, master=false}]
2018-02-08 16:24:02,518 [pool-1-thread-1] DEBUG [org.elasticsearch.transport.netty] - [Raman] connected to node [{node03}{tRpjIa0lS5-awR_CJldlkw}{172.16.23.15}{172.16.23.15:9302}{max_local_storage_nodes=2, master=true}]
2018-02-08 16:24:02,522 [pool-1-thread-1] DEBUG [org.elasticsearch.transport.netty] - [Raman] connected to node [{node01}{QWrvvVLrT8Wlg-yr48Hu8Q}{172.16.23.13}{172.16.23.13:9303}{max_local_storage_nodes=2, master=true}]
2018-02-08 16:24:02,525 [pool-1-thread-1] DEBUG [org.elasticsearch.transport.netty] - [Raman] connected to node [{node04}{5UFptUtFQ0iV4_YH_wXgWQ}{172.16.23.16}{172.16.23.16:9303}{max_local_storage_nodes=2, master=true}]
2018-02-08 16:24:02,526 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.util.ESTools] - ESTools创建Elasticsearch Client 结束
2018-02-08 16:24:02,566 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.ConsumerConfig] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [172.16.10.211:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = spider002
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-02-08 16:24:02,712 [pool-1-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.11.0.1
2018-02-08 16:24:02,712 [pool-1-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : c2a0d5f9b1f45bf5
2018-02-08 16:24:02,864 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Discovered coordinator 172.16.10.211:9092 (id: 2147483647 rack: null) for group spider002.
2018-02-08 16:24:02,877 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Revoking previously assigned partitions [] for group spider002
2018-02-08 16:24:02,877 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - (Re-)joining group spider002
2018-02-08 16:24:02,890 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Successfully joined group spider002 with generation 53
2018-02-08 16:24:02,891 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Setting newly assigned partitions [output-stream-0] for group spider002
2018-02-08 16:24:03,120 [pool-3-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyTopology] - topicConfig.yml
2018-02-08 16:24:03,139 [pool-3-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyTopology] - 创建拓扑成功doNot
2018-02-08 16:24:03,142 [pool-3-thread-1] INFO  [org.apache.kafka.streams.StreamsConfig] - StreamsConfig values: 
	application.id = huipai__exchangeRsteHistory
	application.server = 
	bootstrap.servers = [172.16.10.211:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = 
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	default.timestamp.extractor = class org.apache.kafka.streams.processor.WallclockTimestampExtractor
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	key.serde = null
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	timestamp.extractor = null
	value.serde = null
	windowstore.changelog.additional.retention.ms = 86400000
	zookeeper.connect = 

2018-02-08 16:24:03,186 [pool-3-thread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-b921de7c-6c22-4e3a-a7a3-65df888b5a4e-StreamThread-1] Creating consumer client
2018-02-08 16:24:03,188 [pool-3-thread-1] INFO  [org.apache.kafka.clients.consumer.ConsumerConfig] - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [172.16.10.211:9092]
	check.crcs = true
	client.id = huipai__exchangeRsteHistory-b921de7c-6c22-4e3a-a7a3-65df888b5a4e-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = huipai__exchangeRsteHistory
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-02-08 16:24:03,196 [pool-3-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.11.0.1
2018-02-08 16:24:03,196 [pool-3-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : c2a0d5f9b1f45bf5
2018-02-08 16:24:03,196 [pool-3-thread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-b921de7c-6c22-4e3a-a7a3-65df888b5a4e-StreamThread-1] Creating restore consumer client
2018-02-08 16:24:03,197 [pool-3-thread-1] INFO  [org.apache.kafka.clients.consumer.ConsumerConfig] - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [172.16.10.211:9092]
	check.crcs = true
	client.id = huipai__exchangeRsteHistory-b921de7c-6c22-4e3a-a7a3-65df888b5a4e-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-02-08 16:24:03,200 [pool-3-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.11.0.1
2018-02-08 16:24:03,200 [pool-3-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : c2a0d5f9b1f45bf5
2018-02-08 16:24:03,261 [huipai__exchangeRsteHistory-b921de7c-6c22-4e3a-a7a3-65df888b5a4e-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-b921de7c-6c22-4e3a-a7a3-65df888b5a4e-StreamThread-1] Starting
2018-02-08 16:24:03,261 [huipai__exchangeRsteHistory-b921de7c-6c22-4e3a-a7a3-65df888b5a4e-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-b921de7c-6c22-4e3a-a7a3-65df888b5a4e-StreamThread-1] State transition from CREATED to RUNNING.
2018-02-08 16:24:03,261 [pool-3-thread-1] INFO  [org.apache.kafka.streams.KafkaStreams] - stream-client [huipai__exchangeRsteHistory-b921de7c-6c22-4e3a-a7a3-65df888b5a4e] Started Kafka Stream process
2018-02-08 16:24:03,261 [pool-3-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.Application] - 开启流拓扑
2018-02-08 16:24:03,270 [huipai__exchangeRsteHistory-b921de7c-6c22-4e3a-a7a3-65df888b5a4e-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Discovered coordinator 172.16.10.211:9092 (id: 2147483647 rack: null) for group huipai__exchangeRsteHistory.
2018-02-08 16:24:03,270 [huipai__exchangeRsteHistory-b921de7c-6c22-4e3a-a7a3-65df888b5a4e-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Revoking previously assigned partitions [] for group huipai__exchangeRsteHistory
2018-02-08 16:24:03,270 [huipai__exchangeRsteHistory-b921de7c-6c22-4e3a-a7a3-65df888b5a4e-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-b921de7c-6c22-4e3a-a7a3-65df888b5a4e-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED.
2018-02-08 16:24:03,270 [huipai__exchangeRsteHistory-b921de7c-6c22-4e3a-a7a3-65df888b5a4e-StreamThread-1] INFO  [org.apache.kafka.streams.KafkaStreams] - stream-client [huipai__exchangeRsteHistory-b921de7c-6c22-4e3a-a7a3-65df888b5a4e] State transition from RUNNING to REBALANCING.
2018-02-08 16:24:03,271 [huipai__exchangeRsteHistory-b921de7c-6c22-4e3a-a7a3-65df888b5a4e-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-b921de7c-6c22-4e3a-a7a3-65df888b5a4e-StreamThread-1] partition revocation took 1 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-02-08 16:24:03,271 [huipai__exchangeRsteHistory-b921de7c-6c22-4e3a-a7a3-65df888b5a4e-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - (Re-)joining group huipai__exchangeRsteHistory
2018-02-08 16:24:03,279 [huipai__exchangeRsteHistory-b921de7c-6c22-4e3a-a7a3-65df888b5a4e-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamPartitionAssignor] - stream-thread [huipai__exchangeRsteHistory-b921de7c-6c22-4e3a-a7a3-65df888b5a4e-StreamThread-1] Assigned tasks to clients as {b921de7c-6c22-4e3a-a7a3-65df888b5a4e=[activeTasks: ([0_0]) standbyTasks: ([]) assignedTasks: ([0_0]) prevActiveTasks: ([]) prevAssignedTasks: ([]) capacity: 1]}.
2018-02-08 16:24:03,282 [huipai__exchangeRsteHistory-b921de7c-6c22-4e3a-a7a3-65df888b5a4e-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Successfully joined group huipai__exchangeRsteHistory with generation 28
2018-02-08 16:24:03,283 [huipai__exchangeRsteHistory-b921de7c-6c22-4e3a-a7a3-65df888b5a4e-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Setting newly assigned partitions [huipai__exchangeRsteHistory-0] for group huipai__exchangeRsteHistory
2018-02-08 16:24:03,283 [huipai__exchangeRsteHistory-b921de7c-6c22-4e3a-a7a3-65df888b5a4e-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-b921de7c-6c22-4e3a-a7a3-65df888b5a4e-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED.
2018-02-08 16:24:03,283 [huipai__exchangeRsteHistory-b921de7c-6c22-4e3a-a7a3-65df888b5a4e-StreamThread-1] INFO  [org.apache.kafka.streams.KafkaStreams] - stream-client [huipai__exchangeRsteHistory-b921de7c-6c22-4e3a-a7a3-65df888b5a4e] State transition from REBALANCING to REBALANCING.
2018-02-08 16:24:03,291 [huipai__exchangeRsteHistory-b921de7c-6c22-4e3a-a7a3-65df888b5a4e-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-b921de7c-6c22-4e3a-a7a3-65df888b5a4e-StreamThread-1] Creating shared producer client
2018-02-08 16:24:03,294 [huipai__exchangeRsteHistory-b921de7c-6c22-4e3a-a7a3-65df888b5a4e-StreamThread-1] INFO  [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [172.16.10.211:9092]
	buffer.memory = 33554432
	client.id = huipai__exchangeRsteHistory-b921de7c-6c22-4e3a-a7a3-65df888b5a4e-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-02-08 16:24:03,321 [huipai__exchangeRsteHistory-b921de7c-6c22-4e3a-a7a3-65df888b5a4e-StreamThread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.11.0.1
2018-02-08 16:24:03,321 [huipai__exchangeRsteHistory-b921de7c-6c22-4e3a-a7a3-65df888b5a4e-StreamThread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : c2a0d5f9b1f45bf5
2018-02-08 16:24:03,357 [huipai__exchangeRsteHistory-b921de7c-6c22-4e3a-a7a3-65df888b5a4e-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-b921de7c-6c22-4e3a-a7a3-65df888b5a4e-StreamThread-1] partition assignment took 74 ms.
	current active tasks: [0_0]
	current standby tasks: []
	previous active tasks: []

2018-02-08 16:24:03,365 [huipai__exchangeRsteHistory-b921de7c-6c22-4e3a-a7a3-65df888b5a4e-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-b921de7c-6c22-4e3a-a7a3-65df888b5a4e-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING.
2018-02-08 16:24:03,365 [huipai__exchangeRsteHistory-b921de7c-6c22-4e3a-a7a3-65df888b5a4e-StreamThread-1] INFO  [org.apache.kafka.streams.KafkaStreams] - stream-client [huipai__exchangeRsteHistory-b921de7c-6c22-4e3a-a7a3-65df888b5a4e] State transition from REBALANCING to RUNNING.
2018-02-08 16:27:39,601 [pool-3-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.util.PropertyReaderUtil] - 配置文件被修改
2018-02-08 16:27:39,731 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.util.ESTools] - ESTools开始创建client
2018-02-08 16:27:39,773 [pool-1-thread-1] INFO  [org.elasticsearch.plugins] - [Matador] modules [], plugins [], sites []
2018-02-08 16:27:39,789 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Matador] creating thread_pool [force_merge], type [fixed], size [1], queue_size [null]
2018-02-08 16:27:39,797 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Matador] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
2018-02-08 16:27:39,809 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Matador] creating thread_pool [fetch_shard_started], type [scaling], min [1], size [8], keep_alive [5m]
2018-02-08 16:27:39,810 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Matador] creating thread_pool [listener], type [fixed], size [2], queue_size [null]
2018-02-08 16:27:39,811 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Matador] creating thread_pool [index], type [fixed], size [4], queue_size [200]
2018-02-08 16:27:39,811 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Matador] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
2018-02-08 16:27:39,811 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Matador] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
2018-02-08 16:27:39,811 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Matador] creating thread_pool [generic], type [cached], keep_alive [30s]
2018-02-08 16:27:39,812 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Matador] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
2018-02-08 16:27:39,812 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Matador] creating thread_pool [search], type [fixed], size [7], queue_size [1k]
2018-02-08 16:27:39,813 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Matador] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
2018-02-08 16:27:39,813 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Matador] creating thread_pool [fetch_shard_store], type [scaling], min [1], size [8], keep_alive [5m]
2018-02-08 16:27:39,814 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Matador] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
2018-02-08 16:27:39,814 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Matador] creating thread_pool [get], type [fixed], size [4], queue_size [1k]
2018-02-08 16:27:39,814 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Matador] creating thread_pool [bulk], type [fixed], size [4], queue_size [50]
2018-02-08 16:27:39,814 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Matador] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
2018-02-08 16:27:40,326 [pool-1-thread-1] DEBUG [org.elasticsearch.common.network] - configuration:

lo
        Software Loopback Interface 1
        inet 127.0.0.1 netmask:255.0.0.0 broadcast:127.255.255.255 scope:host
        inet6 ::1 prefixlen:128 scope:host
        UP MULTICAST LOOPBACK mtu:-1 index:1

eth0
        Realtek PCIe GBE Family Controller
        inet 172.16.73.125 netmask:255.255.255.0 broadcast:172.16.73.255 scope:site
        inet6 fe80::52b:2670:705d:338e prefixlen:64 scope:link
        hardware 1C:1B:0D:B1:E1:B3
        UP MULTICAST mtu:1500 index:2

eth1
        Microsoft Kernel Debug Network Adapter
        MULTICAST mtu:-1 index:3

eth2
        Realtek PCIe GBE Family Controller #2
        MULTICAST mtu:-1 index:4

eth3
        Realtek PCIe GBE Family Controller-WFP Native MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:5

eth4
        Realtek PCIe GBE Family Controller-iNode LightWeight Filter-0000
        MULTICAST mtu:-1 index:6

eth5
        Realtek PCIe GBE Family Controller-QoS Packet Scheduler-0000
        MULTICAST mtu:-1 index:7

eth6
        Realtek PCIe GBE Family Controller-WFP 802.3 MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:8

net0
        WAN Miniport (SSTP)
        MULTICAST mtu:-1 index:9

net1
        WAN Miniport (IKEv2)
        MULTICAST mtu:-1 index:10

net2
        WAN Miniport (L2TP)
        MULTICAST mtu:-1 index:11

net3
        WAN Miniport (PPTP)
        MULTICAST mtu:-1 index:12

ppp0
        WAN Miniport (PPPOE)
        MULTICAST mtu:-1 index:13

eth7
        WAN Miniport (IP)
        MULTICAST mtu:-1 index:14

eth8
        WAN Miniport (IP)-WFP Native MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:15

eth9
        WAN Miniport (IP)-iNode LightWeight Filter-0000
        MULTICAST mtu:-1 index:16

eth10
        WAN Miniport (IP)-QoS Packet Scheduler-0000
        MULTICAST mtu:-1 index:17

eth11
        WAN Miniport (IPv6)
        MULTICAST mtu:-1 index:18

eth12
        WAN Miniport (IPv6)-WFP Native MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:19

eth13
        WAN Miniport (IPv6)-iNode LightWeight Filter-0000
        MULTICAST mtu:-1 index:20

eth14
        WAN Miniport (IPv6)-QoS Packet Scheduler-0000
        MULTICAST mtu:-1 index:21

eth15
        WAN Miniport (Network Monitor)
        MULTICAST mtu:-1 index:22

eth16
        WAN Miniport (Network Monitor)-WFP Native MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:23

eth17
        WAN Miniport (Network Monitor)-iNode LightWeight Filter-0000
        MULTICAST mtu:-1 index:24

eth18
        WAN Miniport (Network Monitor)-QoS Packet Scheduler-0000
        MULTICAST mtu:-1 index:25

net4
        Teredo Tunneling Pseudo-Interface
        inet6 2001:0:9d38:6ab8:28ec:1162:53ef:b682 prefixlen:0
        inet6 fe80::28ec:1162:53ef:b682 prefixlen:32 scope:link
        hardware 00:00:00:00:00:00:00:E0
        UP POINTOPOINT mtu:1280 index:26

2018-02-08 16:27:40,354 [pool-1-thread-1] DEBUG [org.elasticsearch.common.netty] - using gathering [true]
2018-02-08 16:27:40,380 [pool-1-thread-1] DEBUG [org.elasticsearch.client.transport] - [Matador] node_sampler_interval[5s]
2018-02-08 16:27:40,394 [pool-1-thread-1] DEBUG [org.elasticsearch.netty.channel.socket.nio.SelectorUtil] - Using select timeout of 500
2018-02-08 16:27:40,394 [pool-1-thread-1] DEBUG [org.elasticsearch.netty.channel.socket.nio.SelectorUtil] - Epoll-bug workaround enabled = false
2018-02-08 16:27:40,422 [pool-1-thread-1] DEBUG [org.elasticsearch.client.transport] - [Matador] adding address [{#transport#-1}{172.16.23.13}{172.16.23.13:9303}]
2018-02-08 16:27:40,440 [elasticsearch[Matador][management][T#1]] DEBUG [org.elasticsearch.transport.netty] - [Matador] connected to node [{#transport#-1}{172.16.23.13}{172.16.23.13:9303}]
2018-02-08 16:27:40,540 [pool-1-thread-1] DEBUG [org.elasticsearch.transport.netty] - [Matador] connected to node [{node02}{phQmsLojTs2ghLCQ4Qd9mg}{172.16.23.15}{172.16.23.15:9303}{max_local_storage_nodes=2, master=false}]
2018-02-08 16:27:40,545 [pool-1-thread-1] DEBUG [org.elasticsearch.transport.netty] - [Matador] connected to node [{node03}{tRpjIa0lS5-awR_CJldlkw}{172.16.23.15}{172.16.23.15:9302}{max_local_storage_nodes=2, master=true}]
2018-02-08 16:27:40,549 [pool-1-thread-1] DEBUG [org.elasticsearch.transport.netty] - [Matador] connected to node [{node01}{QWrvvVLrT8Wlg-yr48Hu8Q}{172.16.23.13}{172.16.23.13:9303}{max_local_storage_nodes=2, master=true}]
2018-02-08 16:27:40,553 [pool-1-thread-1] DEBUG [org.elasticsearch.transport.netty] - [Matador] connected to node [{node04}{5UFptUtFQ0iV4_YH_wXgWQ}{172.16.23.16}{172.16.23.16:9303}{max_local_storage_nodes=2, master=true}]
2018-02-08 16:27:40,553 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.util.ESTools] - ESTools创建Elasticsearch Client 结束
2018-02-08 16:27:40,573 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.ConsumerConfig] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [172.16.10.211:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = spider002
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-02-08 16:27:40,638 [pool-1-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.11.0.1
2018-02-08 16:27:40,638 [pool-1-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : c2a0d5f9b1f45bf5
2018-02-08 16:27:40,717 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Discovered coordinator 172.16.10.211:9092 (id: 2147483647 rack: null) for group spider002.
2018-02-08 16:27:40,720 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Revoking previously assigned partitions [] for group spider002
2018-02-08 16:27:40,720 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - (Re-)joining group spider002
2018-02-08 16:27:40,735 [pool-3-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyTopology] - topicConfig.yml
2018-02-08 16:27:40,774 [pool-3-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyTopology] - 创建拓扑成功doNot
2018-02-08 16:27:40,778 [pool-3-thread-1] INFO  [org.apache.kafka.streams.StreamsConfig] - StreamsConfig values: 
	application.id = huipai__exchangeRsteHistory
	application.server = 
	bootstrap.servers = [172.16.10.211:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = 
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	default.timestamp.extractor = class org.apache.kafka.streams.processor.WallclockTimestampExtractor
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	key.serde = null
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	timestamp.extractor = null
	value.serde = null
	windowstore.changelog.additional.retention.ms = 86400000
	zookeeper.connect = 

2018-02-08 16:27:40,788 [pool-3-thread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-1eda85bb-546e-435b-8d6b-fd326aa22b5e-StreamThread-1] Creating consumer client
2018-02-08 16:27:40,789 [pool-3-thread-1] INFO  [org.apache.kafka.clients.consumer.ConsumerConfig] - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [172.16.10.211:9092]
	check.crcs = true
	client.id = huipai__exchangeRsteHistory-1eda85bb-546e-435b-8d6b-fd326aa22b5e-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = huipai__exchangeRsteHistory
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-02-08 16:27:40,797 [pool-3-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.11.0.1
2018-02-08 16:27:40,798 [pool-3-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : c2a0d5f9b1f45bf5
2018-02-08 16:27:40,798 [pool-3-thread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-1eda85bb-546e-435b-8d6b-fd326aa22b5e-StreamThread-1] Creating restore consumer client
2018-02-08 16:27:40,798 [pool-3-thread-1] INFO  [org.apache.kafka.clients.consumer.ConsumerConfig] - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [172.16.10.211:9092]
	check.crcs = true
	client.id = huipai__exchangeRsteHistory-1eda85bb-546e-435b-8d6b-fd326aa22b5e-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-02-08 16:27:40,800 [pool-3-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.11.0.1
2018-02-08 16:27:40,801 [pool-3-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : c2a0d5f9b1f45bf5
2018-02-08 16:27:40,861 [huipai__exchangeRsteHistory-1eda85bb-546e-435b-8d6b-fd326aa22b5e-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-1eda85bb-546e-435b-8d6b-fd326aa22b5e-StreamThread-1] Starting
2018-02-08 16:27:40,861 [huipai__exchangeRsteHistory-1eda85bb-546e-435b-8d6b-fd326aa22b5e-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-1eda85bb-546e-435b-8d6b-fd326aa22b5e-StreamThread-1] State transition from CREATED to RUNNING.
2018-02-08 16:27:40,861 [pool-3-thread-1] INFO  [org.apache.kafka.streams.KafkaStreams] - stream-client [huipai__exchangeRsteHistory-1eda85bb-546e-435b-8d6b-fd326aa22b5e] Started Kafka Stream process
2018-02-08 16:27:40,861 [pool-3-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.Application] - 开启流拓扑
2018-02-08 16:27:40,867 [huipai__exchangeRsteHistory-1eda85bb-546e-435b-8d6b-fd326aa22b5e-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Discovered coordinator 172.16.10.211:9092 (id: 2147483647 rack: null) for group huipai__exchangeRsteHistory.
2018-02-08 16:27:40,867 [huipai__exchangeRsteHistory-1eda85bb-546e-435b-8d6b-fd326aa22b5e-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Revoking previously assigned partitions [] for group huipai__exchangeRsteHistory
2018-02-08 16:27:40,868 [huipai__exchangeRsteHistory-1eda85bb-546e-435b-8d6b-fd326aa22b5e-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-1eda85bb-546e-435b-8d6b-fd326aa22b5e-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED.
2018-02-08 16:27:40,868 [huipai__exchangeRsteHistory-1eda85bb-546e-435b-8d6b-fd326aa22b5e-StreamThread-1] INFO  [org.apache.kafka.streams.KafkaStreams] - stream-client [huipai__exchangeRsteHistory-1eda85bb-546e-435b-8d6b-fd326aa22b5e] State transition from RUNNING to REBALANCING.
2018-02-08 16:27:40,868 [huipai__exchangeRsteHistory-1eda85bb-546e-435b-8d6b-fd326aa22b5e-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-1eda85bb-546e-435b-8d6b-fd326aa22b5e-StreamThread-1] partition revocation took 0 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-02-08 16:27:40,868 [huipai__exchangeRsteHistory-1eda85bb-546e-435b-8d6b-fd326aa22b5e-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - (Re-)joining group huipai__exchangeRsteHistory
2018-02-08 16:27:40,878 [huipai__exchangeRsteHistory-1eda85bb-546e-435b-8d6b-fd326aa22b5e-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamPartitionAssignor] - stream-thread [huipai__exchangeRsteHistory-1eda85bb-546e-435b-8d6b-fd326aa22b5e-StreamThread-1] Assigned tasks to clients as {1eda85bb-546e-435b-8d6b-fd326aa22b5e=[activeTasks: ([0_0]) standbyTasks: ([]) assignedTasks: ([0_0]) prevActiveTasks: ([]) prevAssignedTasks: ([0_0]) capacity: 1]}.
2018-02-08 16:27:40,882 [huipai__exchangeRsteHistory-1eda85bb-546e-435b-8d6b-fd326aa22b5e-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Successfully joined group huipai__exchangeRsteHistory with generation 30
2018-02-08 16:27:40,882 [huipai__exchangeRsteHistory-1eda85bb-546e-435b-8d6b-fd326aa22b5e-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Setting newly assigned partitions [huipai__exchangeRsteHistory-0] for group huipai__exchangeRsteHistory
2018-02-08 16:27:40,882 [huipai__exchangeRsteHistory-1eda85bb-546e-435b-8d6b-fd326aa22b5e-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-1eda85bb-546e-435b-8d6b-fd326aa22b5e-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED.
2018-02-08 16:27:40,883 [huipai__exchangeRsteHistory-1eda85bb-546e-435b-8d6b-fd326aa22b5e-StreamThread-1] INFO  [org.apache.kafka.streams.KafkaStreams] - stream-client [huipai__exchangeRsteHistory-1eda85bb-546e-435b-8d6b-fd326aa22b5e] State transition from REBALANCING to REBALANCING.
2018-02-08 16:27:40,888 [huipai__exchangeRsteHistory-1eda85bb-546e-435b-8d6b-fd326aa22b5e-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-1eda85bb-546e-435b-8d6b-fd326aa22b5e-StreamThread-1] Creating shared producer client
2018-02-08 16:27:40,891 [huipai__exchangeRsteHistory-1eda85bb-546e-435b-8d6b-fd326aa22b5e-StreamThread-1] INFO  [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [172.16.10.211:9092]
	buffer.memory = 33554432
	client.id = huipai__exchangeRsteHistory-1eda85bb-546e-435b-8d6b-fd326aa22b5e-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-02-08 16:27:40,905 [huipai__exchangeRsteHistory-1eda85bb-546e-435b-8d6b-fd326aa22b5e-StreamThread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.11.0.1
2018-02-08 16:27:40,905 [huipai__exchangeRsteHistory-1eda85bb-546e-435b-8d6b-fd326aa22b5e-StreamThread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : c2a0d5f9b1f45bf5
2018-02-08 16:27:40,914 [huipai__exchangeRsteHistory-1eda85bb-546e-435b-8d6b-fd326aa22b5e-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-1eda85bb-546e-435b-8d6b-fd326aa22b5e-StreamThread-1] partition assignment took 32 ms.
	current active tasks: [0_0]
	current standby tasks: []
	previous active tasks: []

2018-02-08 16:27:40,965 [huipai__exchangeRsteHistory-1eda85bb-546e-435b-8d6b-fd326aa22b5e-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-1eda85bb-546e-435b-8d6b-fd326aa22b5e-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING.
2018-02-08 16:27:40,966 [huipai__exchangeRsteHistory-1eda85bb-546e-435b-8d6b-fd326aa22b5e-StreamThread-1] INFO  [org.apache.kafka.streams.KafkaStreams] - stream-client [huipai__exchangeRsteHistory-1eda85bb-546e-435b-8d6b-fd326aa22b5e] State transition from REBALANCING to RUNNING.
2018-02-08 16:27:41,121 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Successfully joined group spider002 with generation 54
2018-02-08 16:27:41,121 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Setting newly assigned partitions [output-stream-0] for group spider002
2018-02-08 16:30:20,141 [pool-3-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.util.PropertyReaderUtil] - 配置文件被修改
2018-02-08 16:30:20,318 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.util.ESTools] - ESTools开始创建client
2018-02-08 16:30:20,374 [pool-1-thread-1] INFO  [org.elasticsearch.plugins] - [Rodstvow] modules [], plugins [], sites []
2018-02-08 16:30:20,396 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Rodstvow] creating thread_pool [force_merge], type [fixed], size [1], queue_size [null]
2018-02-08 16:30:20,410 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Rodstvow] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
2018-02-08 16:30:20,425 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Rodstvow] creating thread_pool [fetch_shard_started], type [scaling], min [1], size [8], keep_alive [5m]
2018-02-08 16:30:20,427 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Rodstvow] creating thread_pool [listener], type [fixed], size [2], queue_size [null]
2018-02-08 16:30:20,428 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Rodstvow] creating thread_pool [index], type [fixed], size [4], queue_size [200]
2018-02-08 16:30:20,428 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Rodstvow] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
2018-02-08 16:30:20,429 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Rodstvow] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
2018-02-08 16:30:20,429 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Rodstvow] creating thread_pool [generic], type [cached], keep_alive [30s]
2018-02-08 16:30:20,430 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Rodstvow] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
2018-02-08 16:30:20,430 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Rodstvow] creating thread_pool [search], type [fixed], size [7], queue_size [1k]
2018-02-08 16:30:20,431 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Rodstvow] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
2018-02-08 16:30:20,431 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Rodstvow] creating thread_pool [fetch_shard_store], type [scaling], min [1], size [8], keep_alive [5m]
2018-02-08 16:30:20,431 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Rodstvow] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
2018-02-08 16:30:20,434 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Rodstvow] creating thread_pool [get], type [fixed], size [4], queue_size [1k]
2018-02-08 16:30:20,434 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Rodstvow] creating thread_pool [bulk], type [fixed], size [4], queue_size [50]
2018-02-08 16:30:20,434 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Rodstvow] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
2018-02-08 16:30:21,017 [pool-1-thread-1] DEBUG [org.elasticsearch.common.network] - configuration:

lo
        Software Loopback Interface 1
        inet 127.0.0.1 netmask:255.0.0.0 broadcast:127.255.255.255 scope:host
        inet6 ::1 prefixlen:128 scope:host
        UP MULTICAST LOOPBACK mtu:-1 index:1

eth0
        Realtek PCIe GBE Family Controller
        inet 172.16.73.125 netmask:255.255.255.0 broadcast:172.16.73.255 scope:site
        inet6 fe80::52b:2670:705d:338e prefixlen:64 scope:link
        hardware 1C:1B:0D:B1:E1:B3
        UP MULTICAST mtu:1500 index:2

eth1
        Microsoft Kernel Debug Network Adapter
        MULTICAST mtu:-1 index:3

eth2
        Realtek PCIe GBE Family Controller #2
        MULTICAST mtu:-1 index:4

eth3
        Realtek PCIe GBE Family Controller-WFP Native MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:5

eth4
        Realtek PCIe GBE Family Controller-iNode LightWeight Filter-0000
        MULTICAST mtu:-1 index:6

eth5
        Realtek PCIe GBE Family Controller-QoS Packet Scheduler-0000
        MULTICAST mtu:-1 index:7

eth6
        Realtek PCIe GBE Family Controller-WFP 802.3 MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:8

net0
        WAN Miniport (SSTP)
        MULTICAST mtu:-1 index:9

net1
        WAN Miniport (IKEv2)
        MULTICAST mtu:-1 index:10

net2
        WAN Miniport (L2TP)
        MULTICAST mtu:-1 index:11

net3
        WAN Miniport (PPTP)
        MULTICAST mtu:-1 index:12

ppp0
        WAN Miniport (PPPOE)
        MULTICAST mtu:-1 index:13

eth7
        WAN Miniport (IP)
        MULTICAST mtu:-1 index:14

eth8
        WAN Miniport (IP)-WFP Native MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:15

eth9
        WAN Miniport (IP)-iNode LightWeight Filter-0000
        MULTICAST mtu:-1 index:16

eth10
        WAN Miniport (IP)-QoS Packet Scheduler-0000
        MULTICAST mtu:-1 index:17

eth11
        WAN Miniport (IPv6)
        MULTICAST mtu:-1 index:18

eth12
        WAN Miniport (IPv6)-WFP Native MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:19

eth13
        WAN Miniport (IPv6)-iNode LightWeight Filter-0000
        MULTICAST mtu:-1 index:20

eth14
        WAN Miniport (IPv6)-QoS Packet Scheduler-0000
        MULTICAST mtu:-1 index:21

eth15
        WAN Miniport (Network Monitor)
        MULTICAST mtu:-1 index:22

eth16
        WAN Miniport (Network Monitor)-WFP Native MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:23

eth17
        WAN Miniport (Network Monitor)-iNode LightWeight Filter-0000
        MULTICAST mtu:-1 index:24

eth18
        WAN Miniport (Network Monitor)-QoS Packet Scheduler-0000
        MULTICAST mtu:-1 index:25

net4
        Teredo Tunneling Pseudo-Interface
        inet6 2001:0:9d38:6ab8:28ec:1162:53ef:b682 prefixlen:0
        inet6 fe80::28ec:1162:53ef:b682 prefixlen:32 scope:link
        hardware 00:00:00:00:00:00:00:E0
        UP POINTOPOINT mtu:1280 index:26

2018-02-08 16:30:21,048 [pool-1-thread-1] DEBUG [org.elasticsearch.common.netty] - using gathering [true]
2018-02-08 16:30:21,072 [pool-1-thread-1] DEBUG [org.elasticsearch.client.transport] - [Rodstvow] node_sampler_interval[5s]
2018-02-08 16:30:21,091 [pool-1-thread-1] DEBUG [org.elasticsearch.netty.channel.socket.nio.SelectorUtil] - Using select timeout of 500
2018-02-08 16:30:21,091 [pool-1-thread-1] DEBUG [org.elasticsearch.netty.channel.socket.nio.SelectorUtil] - Epoll-bug workaround enabled = false
2018-02-08 16:30:21,130 [pool-1-thread-1] DEBUG [org.elasticsearch.client.transport] - [Rodstvow] adding address [{#transport#-1}{172.16.23.13}{172.16.23.13:9303}]
2018-02-08 16:30:21,152 [elasticsearch[Rodstvow][management][T#1]] DEBUG [org.elasticsearch.transport.netty] - [Rodstvow] connected to node [{#transport#-1}{172.16.23.13}{172.16.23.13:9303}]
2018-02-08 16:30:21,302 [pool-1-thread-1] DEBUG [org.elasticsearch.transport.netty] - [Rodstvow] connected to node [{node02}{phQmsLojTs2ghLCQ4Qd9mg}{172.16.23.15}{172.16.23.15:9303}{max_local_storage_nodes=2, master=false}]
2018-02-08 16:30:21,307 [pool-1-thread-1] DEBUG [org.elasticsearch.transport.netty] - [Rodstvow] connected to node [{node03}{tRpjIa0lS5-awR_CJldlkw}{172.16.23.15}{172.16.23.15:9302}{max_local_storage_nodes=2, master=true}]
2018-02-08 16:30:21,313 [pool-1-thread-1] DEBUG [org.elasticsearch.transport.netty] - [Rodstvow] connected to node [{node01}{QWrvvVLrT8Wlg-yr48Hu8Q}{172.16.23.13}{172.16.23.13:9303}{max_local_storage_nodes=2, master=true}]
2018-02-08 16:30:21,318 [pool-1-thread-1] DEBUG [org.elasticsearch.transport.netty] - [Rodstvow] connected to node [{node04}{5UFptUtFQ0iV4_YH_wXgWQ}{172.16.23.16}{172.16.23.16:9303}{max_local_storage_nodes=2, master=true}]
2018-02-08 16:30:21,318 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.util.ESTools] - ESTools创建Elasticsearch Client 结束
2018-02-08 16:30:21,343 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.ConsumerConfig] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [172.16.10.211:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = spider002
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-02-08 16:30:21,423 [pool-1-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.11.0.1
2018-02-08 16:30:21,437 [pool-1-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : c2a0d5f9b1f45bf5
2018-02-08 16:30:21,553 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Discovered coordinator 172.16.10.211:9092 (id: 2147483647 rack: null) for group spider002.
2018-02-08 16:30:21,555 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Revoking previously assigned partitions [] for group spider002
2018-02-08 16:30:21,555 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - (Re-)joining group spider002
2018-02-08 16:30:21,565 [pool-3-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyTopology] - topicConfig.yml
2018-02-08 16:30:21,613 [pool-3-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyTopology] - 创建拓扑成功doNot
2018-02-08 16:30:21,617 [pool-3-thread-1] INFO  [org.apache.kafka.streams.StreamsConfig] - StreamsConfig values: 
	application.id = huipai__exchangeRsteHistory
	application.server = 
	bootstrap.servers = [172.16.10.211:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = 
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	default.timestamp.extractor = class org.apache.kafka.streams.processor.WallclockTimestampExtractor
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	key.serde = null
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	timestamp.extractor = null
	value.serde = null
	windowstore.changelog.additional.retention.ms = 86400000
	zookeeper.connect = 

2018-02-08 16:30:21,628 [pool-3-thread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-e4acf127-e7c8-4928-98d6-4580ec8a0a01-StreamThread-1] Creating consumer client
2018-02-08 16:30:21,630 [pool-3-thread-1] INFO  [org.apache.kafka.clients.consumer.ConsumerConfig] - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [172.16.10.211:9092]
	check.crcs = true
	client.id = huipai__exchangeRsteHistory-e4acf127-e7c8-4928-98d6-4580ec8a0a01-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = huipai__exchangeRsteHistory
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-02-08 16:30:21,638 [pool-3-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.11.0.1
2018-02-08 16:30:21,638 [pool-3-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : c2a0d5f9b1f45bf5
2018-02-08 16:30:21,638 [pool-3-thread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-e4acf127-e7c8-4928-98d6-4580ec8a0a01-StreamThread-1] Creating restore consumer client
2018-02-08 16:30:21,638 [pool-3-thread-1] INFO  [org.apache.kafka.clients.consumer.ConsumerConfig] - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [172.16.10.211:9092]
	check.crcs = true
	client.id = huipai__exchangeRsteHistory-e4acf127-e7c8-4928-98d6-4580ec8a0a01-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-02-08 16:30:21,641 [pool-3-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.11.0.1
2018-02-08 16:30:21,641 [pool-3-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : c2a0d5f9b1f45bf5
2018-02-08 16:30:21,701 [huipai__exchangeRsteHistory-e4acf127-e7c8-4928-98d6-4580ec8a0a01-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-e4acf127-e7c8-4928-98d6-4580ec8a0a01-StreamThread-1] Starting
2018-02-08 16:30:21,701 [huipai__exchangeRsteHistory-e4acf127-e7c8-4928-98d6-4580ec8a0a01-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-e4acf127-e7c8-4928-98d6-4580ec8a0a01-StreamThread-1] State transition from CREATED to RUNNING.
2018-02-08 16:30:21,702 [pool-3-thread-1] INFO  [org.apache.kafka.streams.KafkaStreams] - stream-client [huipai__exchangeRsteHistory-e4acf127-e7c8-4928-98d6-4580ec8a0a01] Started Kafka Stream process
2018-02-08 16:30:21,702 [pool-3-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.Application] - 开启流拓扑
2018-02-08 16:30:21,708 [huipai__exchangeRsteHistory-e4acf127-e7c8-4928-98d6-4580ec8a0a01-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Discovered coordinator 172.16.10.211:9092 (id: 2147483647 rack: null) for group huipai__exchangeRsteHistory.
2018-02-08 16:30:21,709 [huipai__exchangeRsteHistory-e4acf127-e7c8-4928-98d6-4580ec8a0a01-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Revoking previously assigned partitions [] for group huipai__exchangeRsteHistory
2018-02-08 16:30:21,709 [huipai__exchangeRsteHistory-e4acf127-e7c8-4928-98d6-4580ec8a0a01-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-e4acf127-e7c8-4928-98d6-4580ec8a0a01-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED.
2018-02-08 16:30:21,709 [huipai__exchangeRsteHistory-e4acf127-e7c8-4928-98d6-4580ec8a0a01-StreamThread-1] INFO  [org.apache.kafka.streams.KafkaStreams] - stream-client [huipai__exchangeRsteHistory-e4acf127-e7c8-4928-98d6-4580ec8a0a01] State transition from RUNNING to REBALANCING.
2018-02-08 16:30:21,710 [huipai__exchangeRsteHistory-e4acf127-e7c8-4928-98d6-4580ec8a0a01-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-e4acf127-e7c8-4928-98d6-4580ec8a0a01-StreamThread-1] partition revocation took 1 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-02-08 16:30:21,710 [huipai__exchangeRsteHistory-e4acf127-e7c8-4928-98d6-4580ec8a0a01-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - (Re-)joining group huipai__exchangeRsteHistory
2018-02-08 16:30:21,721 [huipai__exchangeRsteHistory-e4acf127-e7c8-4928-98d6-4580ec8a0a01-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamPartitionAssignor] - stream-thread [huipai__exchangeRsteHistory-e4acf127-e7c8-4928-98d6-4580ec8a0a01-StreamThread-1] Assigned tasks to clients as {e4acf127-e7c8-4928-98d6-4580ec8a0a01=[activeTasks: ([0_0]) standbyTasks: ([]) assignedTasks: ([0_0]) prevActiveTasks: ([]) prevAssignedTasks: ([0_0]) capacity: 1]}.
2018-02-08 16:30:21,725 [huipai__exchangeRsteHistory-e4acf127-e7c8-4928-98d6-4580ec8a0a01-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Successfully joined group huipai__exchangeRsteHistory with generation 32
2018-02-08 16:30:21,726 [huipai__exchangeRsteHistory-e4acf127-e7c8-4928-98d6-4580ec8a0a01-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Setting newly assigned partitions [huipai__exchangeRsteHistory-0] for group huipai__exchangeRsteHistory
2018-02-08 16:30:21,726 [huipai__exchangeRsteHistory-e4acf127-e7c8-4928-98d6-4580ec8a0a01-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-e4acf127-e7c8-4928-98d6-4580ec8a0a01-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED.
2018-02-08 16:30:21,726 [huipai__exchangeRsteHistory-e4acf127-e7c8-4928-98d6-4580ec8a0a01-StreamThread-1] INFO  [org.apache.kafka.streams.KafkaStreams] - stream-client [huipai__exchangeRsteHistory-e4acf127-e7c8-4928-98d6-4580ec8a0a01] State transition from REBALANCING to REBALANCING.
2018-02-08 16:30:21,733 [huipai__exchangeRsteHistory-e4acf127-e7c8-4928-98d6-4580ec8a0a01-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-e4acf127-e7c8-4928-98d6-4580ec8a0a01-StreamThread-1] Creating shared producer client
2018-02-08 16:30:21,736 [huipai__exchangeRsteHistory-e4acf127-e7c8-4928-98d6-4580ec8a0a01-StreamThread-1] INFO  [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [172.16.10.211:9092]
	buffer.memory = 33554432
	client.id = huipai__exchangeRsteHistory-e4acf127-e7c8-4928-98d6-4580ec8a0a01-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-02-08 16:30:21,751 [huipai__exchangeRsteHistory-e4acf127-e7c8-4928-98d6-4580ec8a0a01-StreamThread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.11.0.1
2018-02-08 16:30:21,751 [huipai__exchangeRsteHistory-e4acf127-e7c8-4928-98d6-4580ec8a0a01-StreamThread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : c2a0d5f9b1f45bf5
2018-02-08 16:30:21,759 [huipai__exchangeRsteHistory-e4acf127-e7c8-4928-98d6-4580ec8a0a01-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-e4acf127-e7c8-4928-98d6-4580ec8a0a01-StreamThread-1] partition assignment took 33 ms.
	current active tasks: [0_0]
	current standby tasks: []
	previous active tasks: []

2018-02-08 16:30:21,806 [huipai__exchangeRsteHistory-e4acf127-e7c8-4928-98d6-4580ec8a0a01-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-e4acf127-e7c8-4928-98d6-4580ec8a0a01-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING.
2018-02-08 16:30:21,806 [huipai__exchangeRsteHistory-e4acf127-e7c8-4928-98d6-4580ec8a0a01-StreamThread-1] INFO  [org.apache.kafka.streams.KafkaStreams] - stream-client [huipai__exchangeRsteHistory-e4acf127-e7c8-4928-98d6-4580ec8a0a01] State transition from REBALANCING to RUNNING.
2018-02-08 16:30:22,042 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Successfully joined group spider002 with generation 55
2018-02-08 16:30:22,042 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Setting newly assigned partitions [output-stream-0] for group spider002
2018-02-08 16:32:25,612 [pool-3-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.util.PropertyReaderUtil] - 配置文件被修改
2018-02-08 16:32:25,741 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.util.ESTools] - ESTools开始创建client
2018-02-08 16:32:25,781 [pool-1-thread-1] INFO  [org.elasticsearch.plugins] - [Batwing] modules [], plugins [], sites []
2018-02-08 16:32:25,800 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Batwing] creating thread_pool [force_merge], type [fixed], size [1], queue_size [null]
2018-02-08 16:32:25,808 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Batwing] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
2018-02-08 16:32:25,821 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Batwing] creating thread_pool [fetch_shard_started], type [scaling], min [1], size [8], keep_alive [5m]
2018-02-08 16:32:25,821 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Batwing] creating thread_pool [listener], type [fixed], size [2], queue_size [null]
2018-02-08 16:32:25,821 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Batwing] creating thread_pool [index], type [fixed], size [4], queue_size [200]
2018-02-08 16:32:25,822 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Batwing] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
2018-02-08 16:32:25,822 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Batwing] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
2018-02-08 16:32:25,822 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Batwing] creating thread_pool [generic], type [cached], keep_alive [30s]
2018-02-08 16:32:25,823 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Batwing] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
2018-02-08 16:32:25,823 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Batwing] creating thread_pool [search], type [fixed], size [7], queue_size [1k]
2018-02-08 16:32:25,824 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Batwing] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
2018-02-08 16:32:25,824 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Batwing] creating thread_pool [fetch_shard_store], type [scaling], min [1], size [8], keep_alive [5m]
2018-02-08 16:32:25,824 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Batwing] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
2018-02-08 16:32:25,824 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Batwing] creating thread_pool [get], type [fixed], size [4], queue_size [1k]
2018-02-08 16:32:25,825 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Batwing] creating thread_pool [bulk], type [fixed], size [4], queue_size [50]
2018-02-08 16:32:25,825 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Batwing] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
2018-02-08 16:32:26,332 [pool-1-thread-1] DEBUG [org.elasticsearch.common.network] - configuration:

lo
        Software Loopback Interface 1
        inet 127.0.0.1 netmask:255.0.0.0 broadcast:127.255.255.255 scope:host
        inet6 ::1 prefixlen:128 scope:host
        UP MULTICAST LOOPBACK mtu:-1 index:1

eth0
        Realtek PCIe GBE Family Controller
        inet 172.16.73.125 netmask:255.255.255.0 broadcast:172.16.73.255 scope:site
        inet6 fe80::52b:2670:705d:338e prefixlen:64 scope:link
        hardware 1C:1B:0D:B1:E1:B3
        UP MULTICAST mtu:1500 index:2

eth1
        Microsoft Kernel Debug Network Adapter
        MULTICAST mtu:-1 index:3

eth2
        Realtek PCIe GBE Family Controller #2
        MULTICAST mtu:-1 index:4

eth3
        Realtek PCIe GBE Family Controller-WFP Native MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:5

eth4
        Realtek PCIe GBE Family Controller-iNode LightWeight Filter-0000
        MULTICAST mtu:-1 index:6

eth5
        Realtek PCIe GBE Family Controller-QoS Packet Scheduler-0000
        MULTICAST mtu:-1 index:7

eth6
        Realtek PCIe GBE Family Controller-WFP 802.3 MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:8

net0
        WAN Miniport (SSTP)
        MULTICAST mtu:-1 index:9

net1
        WAN Miniport (IKEv2)
        MULTICAST mtu:-1 index:10

net2
        WAN Miniport (L2TP)
        MULTICAST mtu:-1 index:11

net3
        WAN Miniport (PPTP)
        MULTICAST mtu:-1 index:12

ppp0
        WAN Miniport (PPPOE)
        MULTICAST mtu:-1 index:13

eth7
        WAN Miniport (IP)
        MULTICAST mtu:-1 index:14

eth8
        WAN Miniport (IP)-WFP Native MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:15

eth9
        WAN Miniport (IP)-iNode LightWeight Filter-0000
        MULTICAST mtu:-1 index:16

eth10
        WAN Miniport (IP)-QoS Packet Scheduler-0000
        MULTICAST mtu:-1 index:17

eth11
        WAN Miniport (IPv6)
        MULTICAST mtu:-1 index:18

eth12
        WAN Miniport (IPv6)-WFP Native MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:19

eth13
        WAN Miniport (IPv6)-iNode LightWeight Filter-0000
        MULTICAST mtu:-1 index:20

eth14
        WAN Miniport (IPv6)-QoS Packet Scheduler-0000
        MULTICAST mtu:-1 index:21

eth15
        WAN Miniport (Network Monitor)
        MULTICAST mtu:-1 index:22

eth16
        WAN Miniport (Network Monitor)-WFP Native MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:23

eth17
        WAN Miniport (Network Monitor)-iNode LightWeight Filter-0000
        MULTICAST mtu:-1 index:24

eth18
        WAN Miniport (Network Monitor)-QoS Packet Scheduler-0000
        MULTICAST mtu:-1 index:25

net4
        Teredo Tunneling Pseudo-Interface
        inet6 2001:0:9d38:6ab8:28ec:1162:53ef:b682 prefixlen:0
        inet6 fe80::28ec:1162:53ef:b682 prefixlen:32 scope:link
        hardware 00:00:00:00:00:00:00:E0
        UP POINTOPOINT mtu:1280 index:26

2018-02-08 16:32:26,358 [pool-1-thread-1] DEBUG [org.elasticsearch.common.netty] - using gathering [true]
2018-02-08 16:32:26,379 [pool-1-thread-1] DEBUG [org.elasticsearch.client.transport] - [Batwing] node_sampler_interval[5s]
2018-02-08 16:32:26,394 [pool-1-thread-1] DEBUG [org.elasticsearch.netty.channel.socket.nio.SelectorUtil] - Using select timeout of 500
2018-02-08 16:32:26,394 [pool-1-thread-1] DEBUG [org.elasticsearch.netty.channel.socket.nio.SelectorUtil] - Epoll-bug workaround enabled = false
2018-02-08 16:32:26,422 [pool-1-thread-1] DEBUG [org.elasticsearch.client.transport] - [Batwing] adding address [{#transport#-1}{172.16.23.13}{172.16.23.13:9303}]
2018-02-08 16:32:26,440 [elasticsearch[Batwing][management][T#1]] DEBUG [org.elasticsearch.transport.netty] - [Batwing] connected to node [{#transport#-1}{172.16.23.13}{172.16.23.13:9303}]
2018-02-08 16:32:26,538 [pool-1-thread-1] DEBUG [org.elasticsearch.transport.netty] - [Batwing] connected to node [{node02}{phQmsLojTs2ghLCQ4Qd9mg}{172.16.23.15}{172.16.23.15:9303}{max_local_storage_nodes=2, master=false}]
2018-02-08 16:32:26,544 [pool-1-thread-1] DEBUG [org.elasticsearch.transport.netty] - [Batwing] connected to node [{node03}{tRpjIa0lS5-awR_CJldlkw}{172.16.23.15}{172.16.23.15:9302}{max_local_storage_nodes=2, master=true}]
2018-02-08 16:32:26,550 [pool-1-thread-1] DEBUG [org.elasticsearch.transport.netty] - [Batwing] connected to node [{node01}{QWrvvVLrT8Wlg-yr48Hu8Q}{172.16.23.13}{172.16.23.13:9303}{max_local_storage_nodes=2, master=true}]
2018-02-08 16:32:26,554 [pool-1-thread-1] DEBUG [org.elasticsearch.transport.netty] - [Batwing] connected to node [{node04}{5UFptUtFQ0iV4_YH_wXgWQ}{172.16.23.16}{172.16.23.16:9303}{max_local_storage_nodes=2, master=true}]
2018-02-08 16:32:26,555 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.util.ESTools] - ESTools创建Elasticsearch Client 结束
2018-02-08 16:32:26,574 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.ConsumerConfig] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [172.16.10.211:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = spider002
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-02-08 16:32:26,657 [pool-1-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.11.0.1
2018-02-08 16:32:26,657 [pool-1-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : c2a0d5f9b1f45bf5
2018-02-08 16:32:26,763 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Discovered coordinator 172.16.10.211:9092 (id: 2147483647 rack: null) for group spider002.
2018-02-08 16:32:26,768 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Revoking previously assigned partitions [] for group spider002
2018-02-08 16:32:26,768 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - (Re-)joining group spider002
2018-02-08 16:32:26,779 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Successfully joined group spider002 with generation 57
2018-02-08 16:32:26,780 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Setting newly assigned partitions [output-stream-0] for group spider002
2018-02-08 16:32:26,831 [pool-3-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyTopology] - topicConfig.yml
2018-02-08 16:32:26,841 [pool-3-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyTopology] - 创建拓扑成功doNot
2018-02-08 16:32:26,845 [pool-3-thread-1] INFO  [org.apache.kafka.streams.StreamsConfig] - StreamsConfig values: 
	application.id = huipai__exchangeRsteHistory
	application.server = 
	bootstrap.servers = [172.16.10.211:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = 
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	default.timestamp.extractor = class org.apache.kafka.streams.processor.WallclockTimestampExtractor
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	key.serde = null
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	timestamp.extractor = null
	value.serde = null
	windowstore.changelog.additional.retention.ms = 86400000
	zookeeper.connect = 

2018-02-08 16:32:26,862 [pool-3-thread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-8c69103b-21e2-4292-8edf-70e4bbe3cd41-StreamThread-1] Creating consumer client
2018-02-08 16:32:26,864 [pool-3-thread-1] INFO  [org.apache.kafka.clients.consumer.ConsumerConfig] - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [172.16.10.211:9092]
	check.crcs = true
	client.id = huipai__exchangeRsteHistory-8c69103b-21e2-4292-8edf-70e4bbe3cd41-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = huipai__exchangeRsteHistory
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-02-08 16:32:26,877 [pool-3-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.11.0.1
2018-02-08 16:32:26,877 [pool-3-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : c2a0d5f9b1f45bf5
2018-02-08 16:32:26,877 [pool-3-thread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-8c69103b-21e2-4292-8edf-70e4bbe3cd41-StreamThread-1] Creating restore consumer client
2018-02-08 16:32:26,878 [pool-3-thread-1] INFO  [org.apache.kafka.clients.consumer.ConsumerConfig] - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [172.16.10.211:9092]
	check.crcs = true
	client.id = huipai__exchangeRsteHistory-8c69103b-21e2-4292-8edf-70e4bbe3cd41-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-02-08 16:32:26,886 [pool-3-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.11.0.1
2018-02-08 16:32:26,886 [pool-3-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : c2a0d5f9b1f45bf5
2018-02-08 16:32:26,953 [huipai__exchangeRsteHistory-8c69103b-21e2-4292-8edf-70e4bbe3cd41-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-8c69103b-21e2-4292-8edf-70e4bbe3cd41-StreamThread-1] Starting
2018-02-08 16:32:26,953 [huipai__exchangeRsteHistory-8c69103b-21e2-4292-8edf-70e4bbe3cd41-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-8c69103b-21e2-4292-8edf-70e4bbe3cd41-StreamThread-1] State transition from CREATED to RUNNING.
2018-02-08 16:32:26,953 [pool-3-thread-1] INFO  [org.apache.kafka.streams.KafkaStreams] - stream-client [huipai__exchangeRsteHistory-8c69103b-21e2-4292-8edf-70e4bbe3cd41] Started Kafka Stream process
2018-02-08 16:32:26,953 [pool-3-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.Application] - 开启流拓扑
2018-02-08 16:32:26,959 [huipai__exchangeRsteHistory-8c69103b-21e2-4292-8edf-70e4bbe3cd41-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Discovered coordinator 172.16.10.211:9092 (id: 2147483647 rack: null) for group huipai__exchangeRsteHistory.
2018-02-08 16:32:26,959 [huipai__exchangeRsteHistory-8c69103b-21e2-4292-8edf-70e4bbe3cd41-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Revoking previously assigned partitions [] for group huipai__exchangeRsteHistory
2018-02-08 16:32:26,960 [huipai__exchangeRsteHistory-8c69103b-21e2-4292-8edf-70e4bbe3cd41-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-8c69103b-21e2-4292-8edf-70e4bbe3cd41-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED.
2018-02-08 16:32:26,960 [huipai__exchangeRsteHistory-8c69103b-21e2-4292-8edf-70e4bbe3cd41-StreamThread-1] INFO  [org.apache.kafka.streams.KafkaStreams] - stream-client [huipai__exchangeRsteHistory-8c69103b-21e2-4292-8edf-70e4bbe3cd41] State transition from RUNNING to REBALANCING.
2018-02-08 16:32:26,960 [huipai__exchangeRsteHistory-8c69103b-21e2-4292-8edf-70e4bbe3cd41-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-8c69103b-21e2-4292-8edf-70e4bbe3cd41-StreamThread-1] partition revocation took 1 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-02-08 16:32:26,960 [huipai__exchangeRsteHistory-8c69103b-21e2-4292-8edf-70e4bbe3cd41-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - (Re-)joining group huipai__exchangeRsteHistory
2018-02-08 16:32:26,970 [huipai__exchangeRsteHistory-8c69103b-21e2-4292-8edf-70e4bbe3cd41-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamPartitionAssignor] - stream-thread [huipai__exchangeRsteHistory-8c69103b-21e2-4292-8edf-70e4bbe3cd41-StreamThread-1] Assigned tasks to clients as {8c69103b-21e2-4292-8edf-70e4bbe3cd41=[activeTasks: ([0_0]) standbyTasks: ([]) assignedTasks: ([0_0]) prevActiveTasks: ([]) prevAssignedTasks: ([0_0]) capacity: 1]}.
2018-02-08 16:32:26,972 [huipai__exchangeRsteHistory-8c69103b-21e2-4292-8edf-70e4bbe3cd41-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Successfully joined group huipai__exchangeRsteHistory with generation 34
2018-02-08 16:32:26,973 [huipai__exchangeRsteHistory-8c69103b-21e2-4292-8edf-70e4bbe3cd41-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Setting newly assigned partitions [huipai__exchangeRsteHistory-0] for group huipai__exchangeRsteHistory
2018-02-08 16:32:26,973 [huipai__exchangeRsteHistory-8c69103b-21e2-4292-8edf-70e4bbe3cd41-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-8c69103b-21e2-4292-8edf-70e4bbe3cd41-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED.
2018-02-08 16:32:26,973 [huipai__exchangeRsteHistory-8c69103b-21e2-4292-8edf-70e4bbe3cd41-StreamThread-1] INFO  [org.apache.kafka.streams.KafkaStreams] - stream-client [huipai__exchangeRsteHistory-8c69103b-21e2-4292-8edf-70e4bbe3cd41] State transition from REBALANCING to REBALANCING.
2018-02-08 16:32:26,980 [huipai__exchangeRsteHistory-8c69103b-21e2-4292-8edf-70e4bbe3cd41-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-8c69103b-21e2-4292-8edf-70e4bbe3cd41-StreamThread-1] Creating shared producer client
2018-02-08 16:32:26,993 [huipai__exchangeRsteHistory-8c69103b-21e2-4292-8edf-70e4bbe3cd41-StreamThread-1] INFO  [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [172.16.10.211:9092]
	buffer.memory = 33554432
	client.id = huipai__exchangeRsteHistory-8c69103b-21e2-4292-8edf-70e4bbe3cd41-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-02-08 16:32:27,024 [huipai__exchangeRsteHistory-8c69103b-21e2-4292-8edf-70e4bbe3cd41-StreamThread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.11.0.1
2018-02-08 16:32:27,025 [huipai__exchangeRsteHistory-8c69103b-21e2-4292-8edf-70e4bbe3cd41-StreamThread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : c2a0d5f9b1f45bf5
2018-02-08 16:32:27,042 [huipai__exchangeRsteHistory-8c69103b-21e2-4292-8edf-70e4bbe3cd41-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-8c69103b-21e2-4292-8edf-70e4bbe3cd41-StreamThread-1] partition assignment took 69 ms.
	current active tasks: [0_0]
	current standby tasks: []
	previous active tasks: []

2018-02-08 16:32:27,061 [huipai__exchangeRsteHistory-8c69103b-21e2-4292-8edf-70e4bbe3cd41-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-8c69103b-21e2-4292-8edf-70e4bbe3cd41-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING.
2018-02-08 16:32:27,061 [huipai__exchangeRsteHistory-8c69103b-21e2-4292-8edf-70e4bbe3cd41-StreamThread-1] INFO  [org.apache.kafka.streams.KafkaStreams] - stream-client [huipai__exchangeRsteHistory-8c69103b-21e2-4292-8edf-70e4bbe3cd41] State transition from REBALANCING to RUNNING.
2018-02-08 16:38:26,202 [pool-3-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.util.PropertyReaderUtil] - 配置文件被修改
2018-02-08 16:38:26,339 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.util.ESTools] - ESTools开始创建client
2018-02-08 16:38:26,380 [pool-1-thread-1] INFO  [org.elasticsearch.plugins] - [Gavel] modules [], plugins [], sites []
2018-02-08 16:38:26,396 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Gavel] creating thread_pool [force_merge], type [fixed], size [1], queue_size [null]
2018-02-08 16:38:26,405 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Gavel] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
2018-02-08 16:38:26,416 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Gavel] creating thread_pool [fetch_shard_started], type [scaling], min [1], size [8], keep_alive [5m]
2018-02-08 16:38:26,417 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Gavel] creating thread_pool [listener], type [fixed], size [2], queue_size [null]
2018-02-08 16:38:26,417 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Gavel] creating thread_pool [index], type [fixed], size [4], queue_size [200]
2018-02-08 16:38:26,417 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Gavel] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
2018-02-08 16:38:26,417 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Gavel] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
2018-02-08 16:38:26,417 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Gavel] creating thread_pool [generic], type [cached], keep_alive [30s]
2018-02-08 16:38:26,418 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Gavel] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
2018-02-08 16:38:26,418 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Gavel] creating thread_pool [search], type [fixed], size [7], queue_size [1k]
2018-02-08 16:38:26,419 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Gavel] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
2018-02-08 16:38:26,419 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Gavel] creating thread_pool [fetch_shard_store], type [scaling], min [1], size [8], keep_alive [5m]
2018-02-08 16:38:26,419 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Gavel] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
2018-02-08 16:38:26,420 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Gavel] creating thread_pool [get], type [fixed], size [4], queue_size [1k]
2018-02-08 16:38:26,420 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Gavel] creating thread_pool [bulk], type [fixed], size [4], queue_size [50]
2018-02-08 16:38:26,420 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Gavel] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
2018-02-08 16:38:26,971 [pool-1-thread-1] DEBUG [org.elasticsearch.common.network] - configuration:

lo
        Software Loopback Interface 1
        inet 127.0.0.1 netmask:255.0.0.0 broadcast:127.255.255.255 scope:host
        inet6 ::1 prefixlen:128 scope:host
        UP MULTICAST LOOPBACK mtu:-1 index:1

eth0
        Realtek PCIe GBE Family Controller
        inet 172.16.73.125 netmask:255.255.255.0 broadcast:172.16.73.255 scope:site
        inet6 fe80::52b:2670:705d:338e prefixlen:64 scope:link
        hardware 1C:1B:0D:B1:E1:B3
        UP MULTICAST mtu:1500 index:2

eth1
        Microsoft Kernel Debug Network Adapter
        MULTICAST mtu:-1 index:3

eth2
        Realtek PCIe GBE Family Controller #2
        MULTICAST mtu:-1 index:4

eth3
        Realtek PCIe GBE Family Controller-WFP Native MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:5

eth4
        Realtek PCIe GBE Family Controller-iNode LightWeight Filter-0000
        MULTICAST mtu:-1 index:6

eth5
        Realtek PCIe GBE Family Controller-QoS Packet Scheduler-0000
        MULTICAST mtu:-1 index:7

eth6
        Realtek PCIe GBE Family Controller-WFP 802.3 MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:8

net0
        WAN Miniport (SSTP)
        MULTICAST mtu:-1 index:9

net1
        WAN Miniport (IKEv2)
        MULTICAST mtu:-1 index:10

net2
        WAN Miniport (L2TP)
        MULTICAST mtu:-1 index:11

net3
        WAN Miniport (PPTP)
        MULTICAST mtu:-1 index:12

ppp0
        WAN Miniport (PPPOE)
        MULTICAST mtu:-1 index:13

eth7
        WAN Miniport (IP)
        MULTICAST mtu:-1 index:14

eth8
        WAN Miniport (IP)-WFP Native MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:15

eth9
        WAN Miniport (IP)-iNode LightWeight Filter-0000
        MULTICAST mtu:-1 index:16

eth10
        WAN Miniport (IP)-QoS Packet Scheduler-0000
        MULTICAST mtu:-1 index:17

eth11
        WAN Miniport (IPv6)
        MULTICAST mtu:-1 index:18

eth12
        WAN Miniport (IPv6)-WFP Native MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:19

eth13
        WAN Miniport (IPv6)-iNode LightWeight Filter-0000
        MULTICAST mtu:-1 index:20

eth14
        WAN Miniport (IPv6)-QoS Packet Scheduler-0000
        MULTICAST mtu:-1 index:21

eth15
        WAN Miniport (Network Monitor)
        MULTICAST mtu:-1 index:22

eth16
        WAN Miniport (Network Monitor)-WFP Native MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:23

eth17
        WAN Miniport (Network Monitor)-iNode LightWeight Filter-0000
        MULTICAST mtu:-1 index:24

eth18
        WAN Miniport (Network Monitor)-QoS Packet Scheduler-0000
        MULTICAST mtu:-1 index:25

net4
        Teredo Tunneling Pseudo-Interface
        inet6 2001:0:9d38:6ab8:28ec:1162:53ef:b682 prefixlen:0
        inet6 fe80::28ec:1162:53ef:b682 prefixlen:32 scope:link
        hardware 00:00:00:00:00:00:00:E0
        UP POINTOPOINT mtu:1280 index:26

2018-02-08 16:38:27,002 [pool-1-thread-1] DEBUG [org.elasticsearch.common.netty] - using gathering [true]
2018-02-08 16:38:27,027 [pool-1-thread-1] DEBUG [org.elasticsearch.client.transport] - [Gavel] node_sampler_interval[5s]
2018-02-08 16:38:27,045 [pool-1-thread-1] DEBUG [org.elasticsearch.netty.channel.socket.nio.SelectorUtil] - Using select timeout of 500
2018-02-08 16:38:27,045 [pool-1-thread-1] DEBUG [org.elasticsearch.netty.channel.socket.nio.SelectorUtil] - Epoll-bug workaround enabled = false
2018-02-08 16:38:27,074 [pool-1-thread-1] DEBUG [org.elasticsearch.client.transport] - [Gavel] adding address [{#transport#-1}{172.16.23.13}{172.16.23.13:9303}]
2018-02-08 16:38:27,094 [elasticsearch[Gavel][management][T#1]] DEBUG [org.elasticsearch.transport.netty] - [Gavel] connected to node [{#transport#-1}{172.16.23.13}{172.16.23.13:9303}]
2018-02-08 16:38:27,200 [pool-1-thread-1] DEBUG [org.elasticsearch.transport.netty] - [Gavel] connected to node [{node02}{phQmsLojTs2ghLCQ4Qd9mg}{172.16.23.15}{172.16.23.15:9303}{max_local_storage_nodes=2, master=false}]
2018-02-08 16:38:27,204 [pool-1-thread-1] DEBUG [org.elasticsearch.transport.netty] - [Gavel] connected to node [{node03}{tRpjIa0lS5-awR_CJldlkw}{172.16.23.15}{172.16.23.15:9302}{max_local_storage_nodes=2, master=true}]
2018-02-08 16:38:27,206 [pool-1-thread-1] DEBUG [org.elasticsearch.transport.netty] - [Gavel] connected to node [{node04}{5UFptUtFQ0iV4_YH_wXgWQ}{172.16.23.16}{172.16.23.16:9303}{max_local_storage_nodes=2, master=true}]
2018-02-08 16:38:27,210 [pool-1-thread-1] DEBUG [org.elasticsearch.transport.netty] - [Gavel] connected to node [{node01}{QWrvvVLrT8Wlg-yr48Hu8Q}{172.16.23.13}{172.16.23.13:9303}{max_local_storage_nodes=2, master=true}]
2018-02-08 16:38:27,210 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.util.ESTools] - ESTools创建Elasticsearch Client 结束
2018-02-08 16:38:27,228 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.ConsumerConfig] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [172.16.10.211:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = spider002
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-02-08 16:38:27,296 [pool-1-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.11.0.1
2018-02-08 16:38:27,297 [pool-1-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : c2a0d5f9b1f45bf5
2018-02-08 16:38:27,374 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Discovered coordinator 172.16.10.211:9092 (id: 2147483647 rack: null) for group spider002.
2018-02-08 16:38:27,378 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Revoking previously assigned partitions [] for group spider002
2018-02-08 16:38:27,379 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - (Re-)joining group spider002
2018-02-08 16:38:27,389 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Successfully joined group spider002 with generation 59
2018-02-08 16:38:27,390 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Setting newly assigned partitions [output-stream-0] for group spider002
2018-02-08 16:38:27,398 [pool-3-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyTopology] - topicConfig.yml
2018-02-08 16:38:27,405 [pool-3-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyTopology] - 创建拓扑成功doNot
2018-02-08 16:38:27,439 [pool-3-thread-1] INFO  [org.apache.kafka.streams.StreamsConfig] - StreamsConfig values: 
	application.id = huipai__exchangeRsteHistory
	application.server = 
	bootstrap.servers = [172.16.10.211:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = 
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	default.timestamp.extractor = class org.apache.kafka.streams.processor.WallclockTimestampExtractor
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	key.serde = null
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	timestamp.extractor = null
	value.serde = null
	windowstore.changelog.additional.retention.ms = 86400000
	zookeeper.connect = 

2018-02-08 16:38:27,451 [pool-3-thread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-145e1eb7-cbab-4cb0-856a-2f3d5be1040a-StreamThread-1] Creating consumer client
2018-02-08 16:38:27,452 [pool-3-thread-1] INFO  [org.apache.kafka.clients.consumer.ConsumerConfig] - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [172.16.10.211:9092]
	check.crcs = true
	client.id = huipai__exchangeRsteHistory-145e1eb7-cbab-4cb0-856a-2f3d5be1040a-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = huipai__exchangeRsteHistory
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-02-08 16:38:27,460 [pool-3-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.11.0.1
2018-02-08 16:38:27,460 [pool-3-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : c2a0d5f9b1f45bf5
2018-02-08 16:38:27,460 [pool-3-thread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-145e1eb7-cbab-4cb0-856a-2f3d5be1040a-StreamThread-1] Creating restore consumer client
2018-02-08 16:38:27,461 [pool-3-thread-1] INFO  [org.apache.kafka.clients.consumer.ConsumerConfig] - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [172.16.10.211:9092]
	check.crcs = true
	client.id = huipai__exchangeRsteHistory-145e1eb7-cbab-4cb0-856a-2f3d5be1040a-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-02-08 16:38:27,464 [pool-3-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.11.0.1
2018-02-08 16:38:27,464 [pool-3-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : c2a0d5f9b1f45bf5
2018-02-08 16:38:27,524 [huipai__exchangeRsteHistory-145e1eb7-cbab-4cb0-856a-2f3d5be1040a-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-145e1eb7-cbab-4cb0-856a-2f3d5be1040a-StreamThread-1] Starting
2018-02-08 16:38:27,524 [huipai__exchangeRsteHistory-145e1eb7-cbab-4cb0-856a-2f3d5be1040a-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-145e1eb7-cbab-4cb0-856a-2f3d5be1040a-StreamThread-1] State transition from CREATED to RUNNING.
2018-02-08 16:38:27,524 [pool-3-thread-1] INFO  [org.apache.kafka.streams.KafkaStreams] - stream-client [huipai__exchangeRsteHistory-145e1eb7-cbab-4cb0-856a-2f3d5be1040a] Started Kafka Stream process
2018-02-08 16:38:27,525 [pool-3-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.Application] - 开启流拓扑
2018-02-08 16:38:27,530 [huipai__exchangeRsteHistory-145e1eb7-cbab-4cb0-856a-2f3d5be1040a-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Discovered coordinator 172.16.10.211:9092 (id: 2147483647 rack: null) for group huipai__exchangeRsteHistory.
2018-02-08 16:38:27,531 [huipai__exchangeRsteHistory-145e1eb7-cbab-4cb0-856a-2f3d5be1040a-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Revoking previously assigned partitions [] for group huipai__exchangeRsteHistory
2018-02-08 16:38:27,531 [huipai__exchangeRsteHistory-145e1eb7-cbab-4cb0-856a-2f3d5be1040a-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-145e1eb7-cbab-4cb0-856a-2f3d5be1040a-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED.
2018-02-08 16:38:27,531 [huipai__exchangeRsteHistory-145e1eb7-cbab-4cb0-856a-2f3d5be1040a-StreamThread-1] INFO  [org.apache.kafka.streams.KafkaStreams] - stream-client [huipai__exchangeRsteHistory-145e1eb7-cbab-4cb0-856a-2f3d5be1040a] State transition from RUNNING to REBALANCING.
2018-02-08 16:38:27,532 [huipai__exchangeRsteHistory-145e1eb7-cbab-4cb0-856a-2f3d5be1040a-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-145e1eb7-cbab-4cb0-856a-2f3d5be1040a-StreamThread-1] partition revocation took 1 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-02-08 16:38:27,532 [huipai__exchangeRsteHistory-145e1eb7-cbab-4cb0-856a-2f3d5be1040a-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - (Re-)joining group huipai__exchangeRsteHistory
2018-02-08 16:38:27,540 [huipai__exchangeRsteHistory-145e1eb7-cbab-4cb0-856a-2f3d5be1040a-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamPartitionAssignor] - stream-thread [huipai__exchangeRsteHistory-145e1eb7-cbab-4cb0-856a-2f3d5be1040a-StreamThread-1] Assigned tasks to clients as {145e1eb7-cbab-4cb0-856a-2f3d5be1040a=[activeTasks: ([0_0]) standbyTasks: ([]) assignedTasks: ([0_0]) prevActiveTasks: ([]) prevAssignedTasks: ([0_0]) capacity: 1]}.
2018-02-08 16:38:27,544 [huipai__exchangeRsteHistory-145e1eb7-cbab-4cb0-856a-2f3d5be1040a-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Successfully joined group huipai__exchangeRsteHistory with generation 36
2018-02-08 16:38:27,545 [huipai__exchangeRsteHistory-145e1eb7-cbab-4cb0-856a-2f3d5be1040a-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Setting newly assigned partitions [huipai__exchangeRsteHistory-0] for group huipai__exchangeRsteHistory
2018-02-08 16:38:27,545 [huipai__exchangeRsteHistory-145e1eb7-cbab-4cb0-856a-2f3d5be1040a-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-145e1eb7-cbab-4cb0-856a-2f3d5be1040a-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED.
2018-02-08 16:38:27,545 [huipai__exchangeRsteHistory-145e1eb7-cbab-4cb0-856a-2f3d5be1040a-StreamThread-1] INFO  [org.apache.kafka.streams.KafkaStreams] - stream-client [huipai__exchangeRsteHistory-145e1eb7-cbab-4cb0-856a-2f3d5be1040a] State transition from REBALANCING to REBALANCING.
2018-02-08 16:38:27,552 [huipai__exchangeRsteHistory-145e1eb7-cbab-4cb0-856a-2f3d5be1040a-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-145e1eb7-cbab-4cb0-856a-2f3d5be1040a-StreamThread-1] Creating shared producer client
2018-02-08 16:38:27,555 [huipai__exchangeRsteHistory-145e1eb7-cbab-4cb0-856a-2f3d5be1040a-StreamThread-1] INFO  [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [172.16.10.211:9092]
	buffer.memory = 33554432
	client.id = huipai__exchangeRsteHistory-145e1eb7-cbab-4cb0-856a-2f3d5be1040a-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-02-08 16:38:27,570 [huipai__exchangeRsteHistory-145e1eb7-cbab-4cb0-856a-2f3d5be1040a-StreamThread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.11.0.1
2018-02-08 16:38:27,570 [huipai__exchangeRsteHistory-145e1eb7-cbab-4cb0-856a-2f3d5be1040a-StreamThread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : c2a0d5f9b1f45bf5
2018-02-08 16:38:27,581 [huipai__exchangeRsteHistory-145e1eb7-cbab-4cb0-856a-2f3d5be1040a-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-145e1eb7-cbab-4cb0-856a-2f3d5be1040a-StreamThread-1] partition assignment took 36 ms.
	current active tasks: [0_0]
	current standby tasks: []
	previous active tasks: []

2018-02-08 16:38:27,627 [huipai__exchangeRsteHistory-145e1eb7-cbab-4cb0-856a-2f3d5be1040a-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-145e1eb7-cbab-4cb0-856a-2f3d5be1040a-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING.
2018-02-08 16:38:27,629 [huipai__exchangeRsteHistory-145e1eb7-cbab-4cb0-856a-2f3d5be1040a-StreamThread-1] INFO  [org.apache.kafka.streams.KafkaStreams] - stream-client [huipai__exchangeRsteHistory-145e1eb7-cbab-4cb0-856a-2f3d5be1040a] State transition from REBALANCING to RUNNING.
2018-02-08 16:42:01,367 [pool-3-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.util.PropertyReaderUtil] - 配置文件被修改
2018-02-08 16:42:01,497 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.util.ESTools] - ESTools开始创建client
2018-02-08 16:42:01,537 [pool-1-thread-1] INFO  [org.elasticsearch.plugins] - [Moondark] modules [], plugins [], sites []
2018-02-08 16:42:01,558 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Moondark] creating thread_pool [force_merge], type [fixed], size [1], queue_size [null]
2018-02-08 16:42:01,567 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Moondark] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
2018-02-08 16:42:01,579 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Moondark] creating thread_pool [fetch_shard_started], type [scaling], min [1], size [8], keep_alive [5m]
2018-02-08 16:42:01,579 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Moondark] creating thread_pool [listener], type [fixed], size [2], queue_size [null]
2018-02-08 16:42:01,580 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Moondark] creating thread_pool [index], type [fixed], size [4], queue_size [200]
2018-02-08 16:42:01,580 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Moondark] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
2018-02-08 16:42:01,580 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Moondark] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
2018-02-08 16:42:01,580 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Moondark] creating thread_pool [generic], type [cached], keep_alive [30s]
2018-02-08 16:42:01,581 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Moondark] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
2018-02-08 16:42:01,581 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Moondark] creating thread_pool [search], type [fixed], size [7], queue_size [1k]
2018-02-08 16:42:01,582 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Moondark] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
2018-02-08 16:42:01,582 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Moondark] creating thread_pool [fetch_shard_store], type [scaling], min [1], size [8], keep_alive [5m]
2018-02-08 16:42:01,582 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Moondark] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
2018-02-08 16:42:01,582 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Moondark] creating thread_pool [get], type [fixed], size [4], queue_size [1k]
2018-02-08 16:42:01,582 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Moondark] creating thread_pool [bulk], type [fixed], size [4], queue_size [50]
2018-02-08 16:42:01,583 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Moondark] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
2018-02-08 16:42:02,104 [pool-1-thread-1] DEBUG [org.elasticsearch.common.network] - configuration:

lo
        Software Loopback Interface 1
        inet 127.0.0.1 netmask:255.0.0.0 broadcast:127.255.255.255 scope:host
        inet6 ::1 prefixlen:128 scope:host
        UP MULTICAST LOOPBACK mtu:-1 index:1

eth0
        Realtek PCIe GBE Family Controller
        inet 172.16.73.125 netmask:255.255.255.0 broadcast:172.16.73.255 scope:site
        inet6 fe80::52b:2670:705d:338e prefixlen:64 scope:link
        hardware 1C:1B:0D:B1:E1:B3
        UP MULTICAST mtu:1500 index:2

eth1
        Microsoft Kernel Debug Network Adapter
        MULTICAST mtu:-1 index:3

eth2
        Realtek PCIe GBE Family Controller #2
        MULTICAST mtu:-1 index:4

eth3
        Realtek PCIe GBE Family Controller-WFP Native MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:5

eth4
        Realtek PCIe GBE Family Controller-iNode LightWeight Filter-0000
        MULTICAST mtu:-1 index:6

eth5
        Realtek PCIe GBE Family Controller-QoS Packet Scheduler-0000
        MULTICAST mtu:-1 index:7

eth6
        Realtek PCIe GBE Family Controller-WFP 802.3 MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:8

net0
        WAN Miniport (SSTP)
        MULTICAST mtu:-1 index:9

net1
        WAN Miniport (IKEv2)
        MULTICAST mtu:-1 index:10

net2
        WAN Miniport (L2TP)
        MULTICAST mtu:-1 index:11

net3
        WAN Miniport (PPTP)
        MULTICAST mtu:-1 index:12

ppp0
        WAN Miniport (PPPOE)
        MULTICAST mtu:-1 index:13

eth7
        WAN Miniport (IP)
        MULTICAST mtu:-1 index:14

eth8
        WAN Miniport (IP)-WFP Native MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:15

eth9
        WAN Miniport (IP)-iNode LightWeight Filter-0000
        MULTICAST mtu:-1 index:16

eth10
        WAN Miniport (IP)-QoS Packet Scheduler-0000
        MULTICAST mtu:-1 index:17

eth11
        WAN Miniport (IPv6)
        MULTICAST mtu:-1 index:18

eth12
        WAN Miniport (IPv6)-WFP Native MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:19

eth13
        WAN Miniport (IPv6)-iNode LightWeight Filter-0000
        MULTICAST mtu:-1 index:20

eth14
        WAN Miniport (IPv6)-QoS Packet Scheduler-0000
        MULTICAST mtu:-1 index:21

eth15
        WAN Miniport (Network Monitor)
        MULTICAST mtu:-1 index:22

eth16
        WAN Miniport (Network Monitor)-WFP Native MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:23

eth17
        WAN Miniport (Network Monitor)-iNode LightWeight Filter-0000
        MULTICAST mtu:-1 index:24

eth18
        WAN Miniport (Network Monitor)-QoS Packet Scheduler-0000
        MULTICAST mtu:-1 index:25

net4
        Teredo Tunneling Pseudo-Interface
        inet6 2001:0:9d38:6ab8:28ec:1162:53ef:b682 prefixlen:0
        inet6 fe80::28ec:1162:53ef:b682 prefixlen:32 scope:link
        hardware 00:00:00:00:00:00:00:E0
        UP POINTOPOINT mtu:1280 index:26

2018-02-08 16:42:02,129 [pool-1-thread-1] DEBUG [org.elasticsearch.common.netty] - using gathering [true]
2018-02-08 16:42:02,150 [pool-1-thread-1] DEBUG [org.elasticsearch.client.transport] - [Moondark] node_sampler_interval[5s]
2018-02-08 16:42:02,164 [pool-1-thread-1] DEBUG [org.elasticsearch.netty.channel.socket.nio.SelectorUtil] - Using select timeout of 500
2018-02-08 16:42:02,164 [pool-1-thread-1] DEBUG [org.elasticsearch.netty.channel.socket.nio.SelectorUtil] - Epoll-bug workaround enabled = false
2018-02-08 16:42:02,192 [pool-1-thread-1] DEBUG [org.elasticsearch.client.transport] - [Moondark] adding address [{#transport#-1}{172.16.23.13}{172.16.23.13:9303}]
2018-02-08 16:42:02,211 [elasticsearch[Moondark][management][T#1]] DEBUG [org.elasticsearch.transport.netty] - [Moondark] connected to node [{#transport#-1}{172.16.23.13}{172.16.23.13:9303}]
2018-02-08 16:42:02,307 [pool-1-thread-1] DEBUG [org.elasticsearch.transport.netty] - [Moondark] connected to node [{node02}{phQmsLojTs2ghLCQ4Qd9mg}{172.16.23.15}{172.16.23.15:9303}{max_local_storage_nodes=2, master=false}]
2018-02-08 16:42:02,311 [pool-1-thread-1] DEBUG [org.elasticsearch.transport.netty] - [Moondark] connected to node [{node03}{tRpjIa0lS5-awR_CJldlkw}{172.16.23.15}{172.16.23.15:9302}{max_local_storage_nodes=2, master=true}]
2018-02-08 16:42:02,314 [pool-1-thread-1] DEBUG [org.elasticsearch.transport.netty] - [Moondark] connected to node [{node01}{QWrvvVLrT8Wlg-yr48Hu8Q}{172.16.23.13}{172.16.23.13:9303}{max_local_storage_nodes=2, master=true}]
2018-02-08 16:42:02,323 [pool-1-thread-1] DEBUG [org.elasticsearch.transport.netty] - [Moondark] connected to node [{node04}{5UFptUtFQ0iV4_YH_wXgWQ}{172.16.23.16}{172.16.23.16:9303}{max_local_storage_nodes=2, master=true}]
2018-02-08 16:42:02,324 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.util.ESTools] - ESTools创建Elasticsearch Client 结束
2018-02-08 16:42:02,343 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.ConsumerConfig] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [172.16.10.211:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = spider002
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-02-08 16:42:02,410 [pool-1-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.11.0.1
2018-02-08 16:42:02,410 [pool-1-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : c2a0d5f9b1f45bf5
2018-02-08 16:42:02,481 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Discovered coordinator 172.16.10.211:9092 (id: 2147483647 rack: null) for group spider002.
2018-02-08 16:42:02,485 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Revoking previously assigned partitions [] for group spider002
2018-02-08 16:42:02,485 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - (Re-)joining group spider002
2018-02-08 16:42:02,525 [pool-3-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyTopology] - topicConfig.yml
2018-02-08 16:42:02,532 [pool-3-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyTopology] - 创建拓扑成功doNot
2018-02-08 16:42:02,535 [pool-3-thread-1] INFO  [org.apache.kafka.streams.StreamsConfig] - StreamsConfig values: 
	application.id = huipai__exchangeRsteHistory
	application.server = 
	bootstrap.servers = [172.16.10.211:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = 
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	default.timestamp.extractor = class org.apache.kafka.streams.processor.WallclockTimestampExtractor
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	key.serde = null
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	timestamp.extractor = null
	value.serde = null
	windowstore.changelog.additional.retention.ms = 86400000
	zookeeper.connect = 

2018-02-08 16:42:02,535 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Successfully joined group spider002 with generation 61
2018-02-08 16:42:02,535 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Setting newly assigned partitions [output-stream-0] for group spider002
2018-02-08 16:42:02,545 [pool-3-thread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-c62ddb37-a17d-4146-9c17-60027c5da00d-StreamThread-1] Creating consumer client
2018-02-08 16:42:02,547 [pool-3-thread-1] INFO  [org.apache.kafka.clients.consumer.ConsumerConfig] - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [172.16.10.211:9092]
	check.crcs = true
	client.id = huipai__exchangeRsteHistory-c62ddb37-a17d-4146-9c17-60027c5da00d-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = huipai__exchangeRsteHistory
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-02-08 16:42:02,555 [pool-3-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.11.0.1
2018-02-08 16:42:02,555 [pool-3-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : c2a0d5f9b1f45bf5
2018-02-08 16:42:02,555 [pool-3-thread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-c62ddb37-a17d-4146-9c17-60027c5da00d-StreamThread-1] Creating restore consumer client
2018-02-08 16:42:02,555 [pool-3-thread-1] INFO  [org.apache.kafka.clients.consumer.ConsumerConfig] - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [172.16.10.211:9092]
	check.crcs = true
	client.id = huipai__exchangeRsteHistory-c62ddb37-a17d-4146-9c17-60027c5da00d-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-02-08 16:42:02,558 [pool-3-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.11.0.1
2018-02-08 16:42:02,558 [pool-3-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : c2a0d5f9b1f45bf5
2018-02-08 16:42:02,619 [huipai__exchangeRsteHistory-c62ddb37-a17d-4146-9c17-60027c5da00d-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-c62ddb37-a17d-4146-9c17-60027c5da00d-StreamThread-1] Starting
2018-02-08 16:42:02,619 [huipai__exchangeRsteHistory-c62ddb37-a17d-4146-9c17-60027c5da00d-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-c62ddb37-a17d-4146-9c17-60027c5da00d-StreamThread-1] State transition from CREATED to RUNNING.
2018-02-08 16:42:02,619 [pool-3-thread-1] INFO  [org.apache.kafka.streams.KafkaStreams] - stream-client [huipai__exchangeRsteHistory-c62ddb37-a17d-4146-9c17-60027c5da00d] Started Kafka Stream process
2018-02-08 16:42:02,620 [pool-3-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.Application] - 开启流拓扑
2018-02-08 16:42:02,626 [huipai__exchangeRsteHistory-c62ddb37-a17d-4146-9c17-60027c5da00d-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Discovered coordinator 172.16.10.211:9092 (id: 2147483647 rack: null) for group huipai__exchangeRsteHistory.
2018-02-08 16:42:02,626 [huipai__exchangeRsteHistory-c62ddb37-a17d-4146-9c17-60027c5da00d-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Revoking previously assigned partitions [] for group huipai__exchangeRsteHistory
2018-02-08 16:42:02,626 [huipai__exchangeRsteHistory-c62ddb37-a17d-4146-9c17-60027c5da00d-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-c62ddb37-a17d-4146-9c17-60027c5da00d-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED.
2018-02-08 16:42:02,627 [huipai__exchangeRsteHistory-c62ddb37-a17d-4146-9c17-60027c5da00d-StreamThread-1] INFO  [org.apache.kafka.streams.KafkaStreams] - stream-client [huipai__exchangeRsteHistory-c62ddb37-a17d-4146-9c17-60027c5da00d] State transition from RUNNING to REBALANCING.
2018-02-08 16:42:02,627 [huipai__exchangeRsteHistory-c62ddb37-a17d-4146-9c17-60027c5da00d-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-c62ddb37-a17d-4146-9c17-60027c5da00d-StreamThread-1] partition revocation took 1 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-02-08 16:42:02,627 [huipai__exchangeRsteHistory-c62ddb37-a17d-4146-9c17-60027c5da00d-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - (Re-)joining group huipai__exchangeRsteHistory
2018-02-08 16:42:04,563 [huipai__exchangeRsteHistory-c62ddb37-a17d-4146-9c17-60027c5da00d-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamPartitionAssignor] - stream-thread [huipai__exchangeRsteHistory-c62ddb37-a17d-4146-9c17-60027c5da00d-StreamThread-1] Assigned tasks to clients as {c62ddb37-a17d-4146-9c17-60027c5da00d=[activeTasks: ([0_0]) standbyTasks: ([]) assignedTasks: ([0_0]) prevActiveTasks: ([]) prevAssignedTasks: ([0_0]) capacity: 1]}.
2018-02-08 16:42:04,568 [huipai__exchangeRsteHistory-c62ddb37-a17d-4146-9c17-60027c5da00d-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Successfully joined group huipai__exchangeRsteHistory with generation 37
2018-02-08 16:42:04,569 [huipai__exchangeRsteHistory-c62ddb37-a17d-4146-9c17-60027c5da00d-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Setting newly assigned partitions [huipai__exchangeRsteHistory-0] for group huipai__exchangeRsteHistory
2018-02-08 16:42:04,569 [huipai__exchangeRsteHistory-c62ddb37-a17d-4146-9c17-60027c5da00d-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-c62ddb37-a17d-4146-9c17-60027c5da00d-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED.
2018-02-08 16:42:04,569 [huipai__exchangeRsteHistory-c62ddb37-a17d-4146-9c17-60027c5da00d-StreamThread-1] INFO  [org.apache.kafka.streams.KafkaStreams] - stream-client [huipai__exchangeRsteHistory-c62ddb37-a17d-4146-9c17-60027c5da00d] State transition from REBALANCING to REBALANCING.
2018-02-08 16:42:04,575 [huipai__exchangeRsteHistory-c62ddb37-a17d-4146-9c17-60027c5da00d-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-c62ddb37-a17d-4146-9c17-60027c5da00d-StreamThread-1] Creating shared producer client
2018-02-08 16:42:04,578 [huipai__exchangeRsteHistory-c62ddb37-a17d-4146-9c17-60027c5da00d-StreamThread-1] INFO  [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [172.16.10.211:9092]
	buffer.memory = 33554432
	client.id = huipai__exchangeRsteHistory-c62ddb37-a17d-4146-9c17-60027c5da00d-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-02-08 16:42:04,590 [huipai__exchangeRsteHistory-c62ddb37-a17d-4146-9c17-60027c5da00d-StreamThread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.11.0.1
2018-02-08 16:42:04,590 [huipai__exchangeRsteHistory-c62ddb37-a17d-4146-9c17-60027c5da00d-StreamThread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : c2a0d5f9b1f45bf5
2018-02-08 16:42:04,599 [huipai__exchangeRsteHistory-c62ddb37-a17d-4146-9c17-60027c5da00d-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-c62ddb37-a17d-4146-9c17-60027c5da00d-StreamThread-1] partition assignment took 30 ms.
	current active tasks: [0_0]
	current standby tasks: []
	previous active tasks: []

2018-02-08 16:42:04,605 [huipai__exchangeRsteHistory-c62ddb37-a17d-4146-9c17-60027c5da00d-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-c62ddb37-a17d-4146-9c17-60027c5da00d-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING.
2018-02-08 16:42:04,605 [huipai__exchangeRsteHistory-c62ddb37-a17d-4146-9c17-60027c5da00d-StreamThread-1] INFO  [org.apache.kafka.streams.KafkaStreams] - stream-client [huipai__exchangeRsteHistory-c62ddb37-a17d-4146-9c17-60027c5da00d] State transition from REBALANCING to RUNNING.
2018-02-08 16:43:11,108 [pool-3-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.util.PropertyReaderUtil] - 配置文件被修改
2018-02-08 16:43:11,239 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.util.ESTools] - ESTools开始创建client
2018-02-08 16:43:11,281 [pool-1-thread-1] INFO  [org.elasticsearch.plugins] - [Vakume] modules [], plugins [], sites []
2018-02-08 16:43:11,296 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Vakume] creating thread_pool [force_merge], type [fixed], size [1], queue_size [null]
2018-02-08 16:43:11,304 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Vakume] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
2018-02-08 16:43:11,317 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Vakume] creating thread_pool [fetch_shard_started], type [scaling], min [1], size [8], keep_alive [5m]
2018-02-08 16:43:11,318 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Vakume] creating thread_pool [listener], type [fixed], size [2], queue_size [null]
2018-02-08 16:43:11,318 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Vakume] creating thread_pool [index], type [fixed], size [4], queue_size [200]
2018-02-08 16:43:11,318 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Vakume] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
2018-02-08 16:43:11,318 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Vakume] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
2018-02-08 16:43:11,319 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Vakume] creating thread_pool [generic], type [cached], keep_alive [30s]
2018-02-08 16:43:11,319 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Vakume] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
2018-02-08 16:43:11,319 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Vakume] creating thread_pool [search], type [fixed], size [7], queue_size [1k]
2018-02-08 16:43:11,320 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Vakume] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
2018-02-08 16:43:11,320 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Vakume] creating thread_pool [fetch_shard_store], type [scaling], min [1], size [8], keep_alive [5m]
2018-02-08 16:43:11,321 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Vakume] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
2018-02-08 16:43:11,321 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Vakume] creating thread_pool [get], type [fixed], size [4], queue_size [1k]
2018-02-08 16:43:11,321 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Vakume] creating thread_pool [bulk], type [fixed], size [4], queue_size [50]
2018-02-08 16:43:11,321 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Vakume] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
2018-02-08 16:43:11,838 [pool-1-thread-1] DEBUG [org.elasticsearch.common.network] - configuration:

lo
        Software Loopback Interface 1
        inet 127.0.0.1 netmask:255.0.0.0 broadcast:127.255.255.255 scope:host
        inet6 ::1 prefixlen:128 scope:host
        UP MULTICAST LOOPBACK mtu:-1 index:1

eth0
        Realtek PCIe GBE Family Controller
        inet 172.16.73.125 netmask:255.255.255.0 broadcast:172.16.73.255 scope:site
        inet6 fe80::52b:2670:705d:338e prefixlen:64 scope:link
        hardware 1C:1B:0D:B1:E1:B3
        UP MULTICAST mtu:1500 index:2

eth1
        Microsoft Kernel Debug Network Adapter
        MULTICAST mtu:-1 index:3

eth2
        Realtek PCIe GBE Family Controller #2
        MULTICAST mtu:-1 index:4

eth3
        Realtek PCIe GBE Family Controller-WFP Native MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:5

eth4
        Realtek PCIe GBE Family Controller-iNode LightWeight Filter-0000
        MULTICAST mtu:-1 index:6

eth5
        Realtek PCIe GBE Family Controller-QoS Packet Scheduler-0000
        MULTICAST mtu:-1 index:7

eth6
        Realtek PCIe GBE Family Controller-WFP 802.3 MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:8

net0
        WAN Miniport (SSTP)
        MULTICAST mtu:-1 index:9

net1
        WAN Miniport (IKEv2)
        MULTICAST mtu:-1 index:10

net2
        WAN Miniport (L2TP)
        MULTICAST mtu:-1 index:11

net3
        WAN Miniport (PPTP)
        MULTICAST mtu:-1 index:12

ppp0
        WAN Miniport (PPPOE)
        MULTICAST mtu:-1 index:13

eth7
        WAN Miniport (IP)
        MULTICAST mtu:-1 index:14

eth8
        WAN Miniport (IP)-WFP Native MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:15

eth9
        WAN Miniport (IP)-iNode LightWeight Filter-0000
        MULTICAST mtu:-1 index:16

eth10
        WAN Miniport (IP)-QoS Packet Scheduler-0000
        MULTICAST mtu:-1 index:17

eth11
        WAN Miniport (IPv6)
        MULTICAST mtu:-1 index:18

eth12
        WAN Miniport (IPv6)-WFP Native MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:19

eth13
        WAN Miniport (IPv6)-iNode LightWeight Filter-0000
        MULTICAST mtu:-1 index:20

eth14
        WAN Miniport (IPv6)-QoS Packet Scheduler-0000
        MULTICAST mtu:-1 index:21

eth15
        WAN Miniport (Network Monitor)
        MULTICAST mtu:-1 index:22

eth16
        WAN Miniport (Network Monitor)-WFP Native MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:23

eth17
        WAN Miniport (Network Monitor)-iNode LightWeight Filter-0000
        MULTICAST mtu:-1 index:24

eth18
        WAN Miniport (Network Monitor)-QoS Packet Scheduler-0000
        MULTICAST mtu:-1 index:25

net4
        Teredo Tunneling Pseudo-Interface
        inet6 2001:0:9d38:6ab8:28ec:1162:53ef:b682 prefixlen:0
        inet6 fe80::28ec:1162:53ef:b682 prefixlen:32 scope:link
        hardware 00:00:00:00:00:00:00:E0
        UP POINTOPOINT mtu:1280 index:26

2018-02-08 16:43:11,864 [pool-1-thread-1] DEBUG [org.elasticsearch.common.netty] - using gathering [true]
2018-02-08 16:43:11,886 [pool-1-thread-1] DEBUG [org.elasticsearch.client.transport] - [Vakume] node_sampler_interval[5s]
2018-02-08 16:43:11,900 [pool-1-thread-1] DEBUG [org.elasticsearch.netty.channel.socket.nio.SelectorUtil] - Using select timeout of 500
2018-02-08 16:43:11,900 [pool-1-thread-1] DEBUG [org.elasticsearch.netty.channel.socket.nio.SelectorUtil] - Epoll-bug workaround enabled = false
2018-02-08 16:43:11,927 [pool-1-thread-1] DEBUG [org.elasticsearch.client.transport] - [Vakume] adding address [{#transport#-1}{172.16.23.13}{172.16.23.13:9303}]
2018-02-08 16:43:11,946 [elasticsearch[Vakume][management][T#1]] DEBUG [org.elasticsearch.transport.netty] - [Vakume] connected to node [{#transport#-1}{172.16.23.13}{172.16.23.13:9303}]
2018-02-08 16:43:12,041 [pool-1-thread-1] DEBUG [org.elasticsearch.transport.netty] - [Vakume] connected to node [{node02}{phQmsLojTs2ghLCQ4Qd9mg}{172.16.23.15}{172.16.23.15:9303}{max_local_storage_nodes=2, master=false}]
2018-02-08 16:43:12,047 [pool-1-thread-1] DEBUG [org.elasticsearch.transport.netty] - [Vakume] connected to node [{node03}{tRpjIa0lS5-awR_CJldlkw}{172.16.23.15}{172.16.23.15:9302}{max_local_storage_nodes=2, master=true}]
2018-02-08 16:43:12,050 [pool-1-thread-1] DEBUG [org.elasticsearch.transport.netty] - [Vakume] connected to node [{node04}{5UFptUtFQ0iV4_YH_wXgWQ}{172.16.23.16}{172.16.23.16:9303}{max_local_storage_nodes=2, master=true}]
2018-02-08 16:43:12,054 [pool-1-thread-1] DEBUG [org.elasticsearch.transport.netty] - [Vakume] connected to node [{node01}{QWrvvVLrT8Wlg-yr48Hu8Q}{172.16.23.13}{172.16.23.13:9303}{max_local_storage_nodes=2, master=true}]
2018-02-08 16:43:12,054 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.util.ESTools] - ESTools创建Elasticsearch Client 结束
2018-02-08 16:43:12,075 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.ConsumerConfig] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [172.16.10.211:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = spider002
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-02-08 16:43:12,140 [pool-1-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.11.0.1
2018-02-08 16:43:12,140 [pool-1-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : c2a0d5f9b1f45bf5
2018-02-08 16:43:12,216 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Discovered coordinator 172.16.10.211:9092 (id: 2147483647 rack: null) for group spider002.
2018-02-08 16:43:12,219 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Revoking previously assigned partitions [] for group spider002
2018-02-08 16:43:12,219 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - (Re-)joining group spider002
2018-02-08 16:43:12,229 [pool-3-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyTopology] - topicConfig.yml
2018-02-08 16:43:12,261 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Successfully joined group spider002 with generation 63
2018-02-08 16:43:12,261 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Setting newly assigned partitions [output-stream-0] for group spider002
2018-02-08 16:43:12,266 [pool-3-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyTopology] - 创建拓扑成功doNot
2018-02-08 16:43:12,269 [pool-3-thread-1] INFO  [org.apache.kafka.streams.StreamsConfig] - StreamsConfig values: 
	application.id = huipai__exchangeRsteHistory
	application.server = 
	bootstrap.servers = [172.16.10.211:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = 
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	default.timestamp.extractor = class org.apache.kafka.streams.processor.WallclockTimestampExtractor
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	key.serde = null
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	timestamp.extractor = null
	value.serde = null
	windowstore.changelog.additional.retention.ms = 86400000
	zookeeper.connect = 

2018-02-08 16:43:12,279 [pool-3-thread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-ddcf6ce5-071d-4e44-82ea-41a98fe74079-StreamThread-1] Creating consumer client
2018-02-08 16:43:12,280 [pool-3-thread-1] INFO  [org.apache.kafka.clients.consumer.ConsumerConfig] - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [172.16.10.211:9092]
	check.crcs = true
	client.id = huipai__exchangeRsteHistory-ddcf6ce5-071d-4e44-82ea-41a98fe74079-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = huipai__exchangeRsteHistory
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-02-08 16:43:12,288 [pool-3-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.11.0.1
2018-02-08 16:43:12,289 [pool-3-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : c2a0d5f9b1f45bf5
2018-02-08 16:43:12,289 [pool-3-thread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-ddcf6ce5-071d-4e44-82ea-41a98fe74079-StreamThread-1] Creating restore consumer client
2018-02-08 16:43:12,289 [pool-3-thread-1] INFO  [org.apache.kafka.clients.consumer.ConsumerConfig] - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [172.16.10.211:9092]
	check.crcs = true
	client.id = huipai__exchangeRsteHistory-ddcf6ce5-071d-4e44-82ea-41a98fe74079-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-02-08 16:43:12,292 [pool-3-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.11.0.1
2018-02-08 16:43:12,292 [pool-3-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : c2a0d5f9b1f45bf5
2018-02-08 16:43:12,353 [huipai__exchangeRsteHistory-ddcf6ce5-071d-4e44-82ea-41a98fe74079-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-ddcf6ce5-071d-4e44-82ea-41a98fe74079-StreamThread-1] Starting
2018-02-08 16:43:12,354 [pool-3-thread-1] INFO  [org.apache.kafka.streams.KafkaStreams] - stream-client [huipai__exchangeRsteHistory-ddcf6ce5-071d-4e44-82ea-41a98fe74079] Started Kafka Stream process
2018-02-08 16:43:12,354 [pool-3-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.Application] - 开启流拓扑
2018-02-08 16:43:12,354 [huipai__exchangeRsteHistory-ddcf6ce5-071d-4e44-82ea-41a98fe74079-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-ddcf6ce5-071d-4e44-82ea-41a98fe74079-StreamThread-1] State transition from CREATED to RUNNING.
2018-02-08 16:43:12,362 [huipai__exchangeRsteHistory-ddcf6ce5-071d-4e44-82ea-41a98fe74079-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Discovered coordinator 172.16.10.211:9092 (id: 2147483647 rack: null) for group huipai__exchangeRsteHistory.
2018-02-08 16:43:12,363 [huipai__exchangeRsteHistory-ddcf6ce5-071d-4e44-82ea-41a98fe74079-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Revoking previously assigned partitions [] for group huipai__exchangeRsteHistory
2018-02-08 16:43:12,363 [huipai__exchangeRsteHistory-ddcf6ce5-071d-4e44-82ea-41a98fe74079-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-ddcf6ce5-071d-4e44-82ea-41a98fe74079-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED.
2018-02-08 16:43:12,363 [huipai__exchangeRsteHistory-ddcf6ce5-071d-4e44-82ea-41a98fe74079-StreamThread-1] INFO  [org.apache.kafka.streams.KafkaStreams] - stream-client [huipai__exchangeRsteHistory-ddcf6ce5-071d-4e44-82ea-41a98fe74079] State transition from RUNNING to REBALANCING.
2018-02-08 16:43:12,363 [huipai__exchangeRsteHistory-ddcf6ce5-071d-4e44-82ea-41a98fe74079-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-ddcf6ce5-071d-4e44-82ea-41a98fe74079-StreamThread-1] partition revocation took 0 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-02-08 16:43:12,363 [huipai__exchangeRsteHistory-ddcf6ce5-071d-4e44-82ea-41a98fe74079-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - (Re-)joining group huipai__exchangeRsteHistory
2018-02-08 16:43:12,373 [huipai__exchangeRsteHistory-ddcf6ce5-071d-4e44-82ea-41a98fe74079-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamPartitionAssignor] - stream-thread [huipai__exchangeRsteHistory-ddcf6ce5-071d-4e44-82ea-41a98fe74079-StreamThread-1] Assigned tasks to clients as {ddcf6ce5-071d-4e44-82ea-41a98fe74079=[activeTasks: ([0_0]) standbyTasks: ([]) assignedTasks: ([0_0]) prevActiveTasks: ([]) prevAssignedTasks: ([0_0]) capacity: 1]}.
2018-02-08 16:43:12,375 [huipai__exchangeRsteHistory-ddcf6ce5-071d-4e44-82ea-41a98fe74079-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Successfully joined group huipai__exchangeRsteHistory with generation 39
2018-02-08 16:43:12,376 [huipai__exchangeRsteHistory-ddcf6ce5-071d-4e44-82ea-41a98fe74079-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Setting newly assigned partitions [huipai__exchangeRsteHistory-0] for group huipai__exchangeRsteHistory
2018-02-08 16:43:12,376 [huipai__exchangeRsteHistory-ddcf6ce5-071d-4e44-82ea-41a98fe74079-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-ddcf6ce5-071d-4e44-82ea-41a98fe74079-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED.
2018-02-08 16:43:12,376 [huipai__exchangeRsteHistory-ddcf6ce5-071d-4e44-82ea-41a98fe74079-StreamThread-1] INFO  [org.apache.kafka.streams.KafkaStreams] - stream-client [huipai__exchangeRsteHistory-ddcf6ce5-071d-4e44-82ea-41a98fe74079] State transition from REBALANCING to REBALANCING.
2018-02-08 16:43:12,382 [huipai__exchangeRsteHistory-ddcf6ce5-071d-4e44-82ea-41a98fe74079-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-ddcf6ce5-071d-4e44-82ea-41a98fe74079-StreamThread-1] Creating shared producer client
2018-02-08 16:43:12,385 [huipai__exchangeRsteHistory-ddcf6ce5-071d-4e44-82ea-41a98fe74079-StreamThread-1] INFO  [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [172.16.10.211:9092]
	buffer.memory = 33554432
	client.id = huipai__exchangeRsteHistory-ddcf6ce5-071d-4e44-82ea-41a98fe74079-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-02-08 16:43:12,415 [huipai__exchangeRsteHistory-ddcf6ce5-071d-4e44-82ea-41a98fe74079-StreamThread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.11.0.1
2018-02-08 16:43:12,416 [huipai__exchangeRsteHistory-ddcf6ce5-071d-4e44-82ea-41a98fe74079-StreamThread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : c2a0d5f9b1f45bf5
2018-02-08 16:43:12,426 [huipai__exchangeRsteHistory-ddcf6ce5-071d-4e44-82ea-41a98fe74079-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-ddcf6ce5-071d-4e44-82ea-41a98fe74079-StreamThread-1] partition assignment took 50 ms.
	current active tasks: [0_0]
	current standby tasks: []
	previous active tasks: []

2018-02-08 16:43:12,457 [huipai__exchangeRsteHistory-ddcf6ce5-071d-4e44-82ea-41a98fe74079-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-ddcf6ce5-071d-4e44-82ea-41a98fe74079-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING.
2018-02-08 16:43:12,457 [huipai__exchangeRsteHistory-ddcf6ce5-071d-4e44-82ea-41a98fe74079-StreamThread-1] INFO  [org.apache.kafka.streams.KafkaStreams] - stream-client [huipai__exchangeRsteHistory-ddcf6ce5-071d-4e44-82ea-41a98fe74079] State transition from REBALANCING to RUNNING.
2018-02-08 16:44:14,149 [pool-3-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.util.PropertyReaderUtil] - 配置文件被修改
2018-02-08 16:44:14,280 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.util.ESTools] - ESTools开始创建client
2018-02-08 16:44:14,319 [pool-1-thread-1] INFO  [org.elasticsearch.plugins] - [Thane Ector] modules [], plugins [], sites []
2018-02-08 16:44:14,332 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Thane Ector] creating thread_pool [force_merge], type [fixed], size [1], queue_size [null]
2018-02-08 16:44:14,338 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Thane Ector] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
2018-02-08 16:44:14,349 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Thane Ector] creating thread_pool [fetch_shard_started], type [scaling], min [1], size [8], keep_alive [5m]
2018-02-08 16:44:14,350 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Thane Ector] creating thread_pool [listener], type [fixed], size [2], queue_size [null]
2018-02-08 16:44:14,350 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Thane Ector] creating thread_pool [index], type [fixed], size [4], queue_size [200]
2018-02-08 16:44:14,350 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Thane Ector] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
2018-02-08 16:44:14,350 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Thane Ector] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
2018-02-08 16:44:14,351 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Thane Ector] creating thread_pool [generic], type [cached], keep_alive [30s]
2018-02-08 16:44:14,351 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Thane Ector] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
2018-02-08 16:44:14,351 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Thane Ector] creating thread_pool [search], type [fixed], size [7], queue_size [1k]
2018-02-08 16:44:14,352 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Thane Ector] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
2018-02-08 16:44:14,352 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Thane Ector] creating thread_pool [fetch_shard_store], type [scaling], min [1], size [8], keep_alive [5m]
2018-02-08 16:44:14,353 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Thane Ector] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
2018-02-08 16:44:14,353 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Thane Ector] creating thread_pool [get], type [fixed], size [4], queue_size [1k]
2018-02-08 16:44:14,353 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Thane Ector] creating thread_pool [bulk], type [fixed], size [4], queue_size [50]
2018-02-08 16:44:14,353 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Thane Ector] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
2018-02-08 16:44:14,883 [pool-1-thread-1] DEBUG [org.elasticsearch.common.network] - configuration:

lo
        Software Loopback Interface 1
        inet 127.0.0.1 netmask:255.0.0.0 broadcast:127.255.255.255 scope:host
        inet6 ::1 prefixlen:128 scope:host
        UP MULTICAST LOOPBACK mtu:-1 index:1

eth0
        Realtek PCIe GBE Family Controller
        inet 172.16.73.125 netmask:255.255.255.0 broadcast:172.16.73.255 scope:site
        inet6 fe80::52b:2670:705d:338e prefixlen:64 scope:link
        hardware 1C:1B:0D:B1:E1:B3
        UP MULTICAST mtu:1500 index:2

eth1
        Microsoft Kernel Debug Network Adapter
        MULTICAST mtu:-1 index:3

eth2
        Realtek PCIe GBE Family Controller #2
        MULTICAST mtu:-1 index:4

eth3
        Realtek PCIe GBE Family Controller-WFP Native MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:5

eth4
        Realtek PCIe GBE Family Controller-iNode LightWeight Filter-0000
        MULTICAST mtu:-1 index:6

eth5
        Realtek PCIe GBE Family Controller-QoS Packet Scheduler-0000
        MULTICAST mtu:-1 index:7

eth6
        Realtek PCIe GBE Family Controller-WFP 802.3 MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:8

net0
        WAN Miniport (SSTP)
        MULTICAST mtu:-1 index:9

net1
        WAN Miniport (IKEv2)
        MULTICAST mtu:-1 index:10

net2
        WAN Miniport (L2TP)
        MULTICAST mtu:-1 index:11

net3
        WAN Miniport (PPTP)
        MULTICAST mtu:-1 index:12

ppp0
        WAN Miniport (PPPOE)
        MULTICAST mtu:-1 index:13

eth7
        WAN Miniport (IP)
        MULTICAST mtu:-1 index:14

eth8
        WAN Miniport (IP)-WFP Native MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:15

eth9
        WAN Miniport (IP)-iNode LightWeight Filter-0000
        MULTICAST mtu:-1 index:16

eth10
        WAN Miniport (IP)-QoS Packet Scheduler-0000
        MULTICAST mtu:-1 index:17

eth11
        WAN Miniport (IPv6)
        MULTICAST mtu:-1 index:18

eth12
        WAN Miniport (IPv6)-WFP Native MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:19

eth13
        WAN Miniport (IPv6)-iNode LightWeight Filter-0000
        MULTICAST mtu:-1 index:20

eth14
        WAN Miniport (IPv6)-QoS Packet Scheduler-0000
        MULTICAST mtu:-1 index:21

eth15
        WAN Miniport (Network Monitor)
        MULTICAST mtu:-1 index:22

eth16
        WAN Miniport (Network Monitor)-WFP Native MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:23

eth17
        WAN Miniport (Network Monitor)-iNode LightWeight Filter-0000
        MULTICAST mtu:-1 index:24

eth18
        WAN Miniport (Network Monitor)-QoS Packet Scheduler-0000
        MULTICAST mtu:-1 index:25

net4
        Teredo Tunneling Pseudo-Interface
        inet6 2001:0:9d38:6ab8:28ec:1162:53ef:b682 prefixlen:0
        inet6 fe80::28ec:1162:53ef:b682 prefixlen:32 scope:link
        hardware 00:00:00:00:00:00:00:E0
        UP POINTOPOINT mtu:1280 index:26

2018-02-08 16:44:14,909 [pool-1-thread-1] DEBUG [org.elasticsearch.common.netty] - using gathering [true]
2018-02-08 16:44:14,935 [pool-1-thread-1] DEBUG [org.elasticsearch.client.transport] - [Thane Ector] node_sampler_interval[5s]
2018-02-08 16:44:14,950 [pool-1-thread-1] DEBUG [org.elasticsearch.netty.channel.socket.nio.SelectorUtil] - Using select timeout of 500
2018-02-08 16:44:14,951 [pool-1-thread-1] DEBUG [org.elasticsearch.netty.channel.socket.nio.SelectorUtil] - Epoll-bug workaround enabled = false
2018-02-08 16:44:14,978 [pool-1-thread-1] DEBUG [org.elasticsearch.client.transport] - [Thane Ector] adding address [{#transport#-1}{172.16.23.13}{172.16.23.13:9303}]
2018-02-08 16:44:14,999 [elasticsearch[Thane Ector][management][T#1]] DEBUG [org.elasticsearch.transport.netty] - [Thane Ector] connected to node [{#transport#-1}{172.16.23.13}{172.16.23.13:9303}]
2018-02-08 16:44:15,096 [pool-1-thread-1] DEBUG [org.elasticsearch.transport.netty] - [Thane Ector] connected to node [{node02}{phQmsLojTs2ghLCQ4Qd9mg}{172.16.23.15}{172.16.23.15:9303}{max_local_storage_nodes=2, master=false}]
2018-02-08 16:44:15,099 [pool-1-thread-1] DEBUG [org.elasticsearch.transport.netty] - [Thane Ector] connected to node [{node03}{tRpjIa0lS5-awR_CJldlkw}{172.16.23.15}{172.16.23.15:9302}{max_local_storage_nodes=2, master=true}]
2018-02-08 16:44:15,103 [pool-1-thread-1] DEBUG [org.elasticsearch.transport.netty] - [Thane Ector] connected to node [{node01}{QWrvvVLrT8Wlg-yr48Hu8Q}{172.16.23.13}{172.16.23.13:9303}{max_local_storage_nodes=2, master=true}]
2018-02-08 16:44:15,106 [pool-1-thread-1] DEBUG [org.elasticsearch.transport.netty] - [Thane Ector] connected to node [{node04}{5UFptUtFQ0iV4_YH_wXgWQ}{172.16.23.16}{172.16.23.16:9303}{max_local_storage_nodes=2, master=true}]
2018-02-08 16:44:15,106 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.util.ESTools] - ESTools创建Elasticsearch Client 结束
2018-02-08 16:44:15,124 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.ConsumerConfig] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [172.16.10.211:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = spider002
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-02-08 16:44:15,194 [pool-1-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.11.0.1
2018-02-08 16:44:15,194 [pool-1-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : c2a0d5f9b1f45bf5
2018-02-08 16:44:15,273 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Discovered coordinator 172.16.10.211:9092 (id: 2147483647 rack: null) for group spider002.
2018-02-08 16:44:15,275 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Revoking previously assigned partitions [] for group spider002
2018-02-08 16:44:15,276 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - (Re-)joining group spider002
2018-02-08 16:44:15,285 [pool-3-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyTopology] - topicConfig.yml
2018-02-08 16:44:15,322 [pool-3-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyTopology] - 创建拓扑成功doNot
2018-02-08 16:44:15,325 [pool-3-thread-1] INFO  [org.apache.kafka.streams.StreamsConfig] - StreamsConfig values: 
	application.id = huipai__exchangeRsteHistory
	application.server = 
	bootstrap.servers = [172.16.10.211:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = 
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	default.timestamp.extractor = class org.apache.kafka.streams.processor.WallclockTimestampExtractor
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	key.serde = null
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	timestamp.extractor = null
	value.serde = null
	windowstore.changelog.additional.retention.ms = 86400000
	zookeeper.connect = 

2018-02-08 16:44:15,335 [pool-3-thread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-9d8fb385-20eb-41ab-a8f4-5c33410e3907-StreamThread-1] Creating consumer client
2018-02-08 16:44:15,336 [pool-3-thread-1] INFO  [org.apache.kafka.clients.consumer.ConsumerConfig] - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [172.16.10.211:9092]
	check.crcs = true
	client.id = huipai__exchangeRsteHistory-9d8fb385-20eb-41ab-a8f4-5c33410e3907-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = huipai__exchangeRsteHistory
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-02-08 16:44:15,343 [pool-3-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.11.0.1
2018-02-08 16:44:15,343 [pool-3-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : c2a0d5f9b1f45bf5
2018-02-08 16:44:15,343 [pool-3-thread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-9d8fb385-20eb-41ab-a8f4-5c33410e3907-StreamThread-1] Creating restore consumer client
2018-02-08 16:44:15,344 [pool-3-thread-1] INFO  [org.apache.kafka.clients.consumer.ConsumerConfig] - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [172.16.10.211:9092]
	check.crcs = true
	client.id = huipai__exchangeRsteHistory-9d8fb385-20eb-41ab-a8f4-5c33410e3907-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-02-08 16:44:15,346 [pool-3-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.11.0.1
2018-02-08 16:44:15,346 [pool-3-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : c2a0d5f9b1f45bf5
2018-02-08 16:44:15,407 [huipai__exchangeRsteHistory-9d8fb385-20eb-41ab-a8f4-5c33410e3907-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-9d8fb385-20eb-41ab-a8f4-5c33410e3907-StreamThread-1] Starting
2018-02-08 16:44:15,407 [huipai__exchangeRsteHistory-9d8fb385-20eb-41ab-a8f4-5c33410e3907-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-9d8fb385-20eb-41ab-a8f4-5c33410e3907-StreamThread-1] State transition from CREATED to RUNNING.
2018-02-08 16:44:15,408 [pool-3-thread-1] INFO  [org.apache.kafka.streams.KafkaStreams] - stream-client [huipai__exchangeRsteHistory-9d8fb385-20eb-41ab-a8f4-5c33410e3907] Started Kafka Stream process
2018-02-08 16:44:15,408 [pool-3-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.Application] - 开启流拓扑
2018-02-08 16:44:15,413 [huipai__exchangeRsteHistory-9d8fb385-20eb-41ab-a8f4-5c33410e3907-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Discovered coordinator 172.16.10.211:9092 (id: 2147483647 rack: null) for group huipai__exchangeRsteHistory.
2018-02-08 16:44:15,414 [huipai__exchangeRsteHistory-9d8fb385-20eb-41ab-a8f4-5c33410e3907-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Revoking previously assigned partitions [] for group huipai__exchangeRsteHistory
2018-02-08 16:44:15,414 [huipai__exchangeRsteHistory-9d8fb385-20eb-41ab-a8f4-5c33410e3907-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-9d8fb385-20eb-41ab-a8f4-5c33410e3907-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED.
2018-02-08 16:44:15,414 [huipai__exchangeRsteHistory-9d8fb385-20eb-41ab-a8f4-5c33410e3907-StreamThread-1] INFO  [org.apache.kafka.streams.KafkaStreams] - stream-client [huipai__exchangeRsteHistory-9d8fb385-20eb-41ab-a8f4-5c33410e3907] State transition from RUNNING to REBALANCING.
2018-02-08 16:44:15,414 [huipai__exchangeRsteHistory-9d8fb385-20eb-41ab-a8f4-5c33410e3907-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-9d8fb385-20eb-41ab-a8f4-5c33410e3907-StreamThread-1] partition revocation took 0 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-02-08 16:44:15,414 [huipai__exchangeRsteHistory-9d8fb385-20eb-41ab-a8f4-5c33410e3907-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - (Re-)joining group huipai__exchangeRsteHistory
2018-02-08 16:44:16,384 [huipai__exchangeRsteHistory-9d8fb385-20eb-41ab-a8f4-5c33410e3907-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamPartitionAssignor] - stream-thread [huipai__exchangeRsteHistory-9d8fb385-20eb-41ab-a8f4-5c33410e3907-StreamThread-1] Assigned tasks to clients as {9d8fb385-20eb-41ab-a8f4-5c33410e3907=[activeTasks: ([0_0]) standbyTasks: ([]) assignedTasks: ([0_0]) prevActiveTasks: ([]) prevAssignedTasks: ([0_0]) capacity: 1]}.
2018-02-08 16:44:16,389 [huipai__exchangeRsteHistory-9d8fb385-20eb-41ab-a8f4-5c33410e3907-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Successfully joined group huipai__exchangeRsteHistory with generation 40
2018-02-08 16:44:16,389 [huipai__exchangeRsteHistory-9d8fb385-20eb-41ab-a8f4-5c33410e3907-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Setting newly assigned partitions [huipai__exchangeRsteHistory-0] for group huipai__exchangeRsteHistory
2018-02-08 16:44:16,390 [huipai__exchangeRsteHistory-9d8fb385-20eb-41ab-a8f4-5c33410e3907-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-9d8fb385-20eb-41ab-a8f4-5c33410e3907-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED.
2018-02-08 16:44:16,390 [huipai__exchangeRsteHistory-9d8fb385-20eb-41ab-a8f4-5c33410e3907-StreamThread-1] INFO  [org.apache.kafka.streams.KafkaStreams] - stream-client [huipai__exchangeRsteHistory-9d8fb385-20eb-41ab-a8f4-5c33410e3907] State transition from REBALANCING to REBALANCING.
2018-02-08 16:44:16,395 [huipai__exchangeRsteHistory-9d8fb385-20eb-41ab-a8f4-5c33410e3907-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-9d8fb385-20eb-41ab-a8f4-5c33410e3907-StreamThread-1] Creating shared producer client
2018-02-08 16:44:16,398 [huipai__exchangeRsteHistory-9d8fb385-20eb-41ab-a8f4-5c33410e3907-StreamThread-1] INFO  [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [172.16.10.211:9092]
	buffer.memory = 33554432
	client.id = huipai__exchangeRsteHistory-9d8fb385-20eb-41ab-a8f4-5c33410e3907-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-02-08 16:44:16,410 [huipai__exchangeRsteHistory-9d8fb385-20eb-41ab-a8f4-5c33410e3907-StreamThread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.11.0.1
2018-02-08 16:44:16,410 [huipai__exchangeRsteHistory-9d8fb385-20eb-41ab-a8f4-5c33410e3907-StreamThread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : c2a0d5f9b1f45bf5
2018-02-08 16:44:16,419 [huipai__exchangeRsteHistory-9d8fb385-20eb-41ab-a8f4-5c33410e3907-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-9d8fb385-20eb-41ab-a8f4-5c33410e3907-StreamThread-1] partition assignment took 28 ms.
	current active tasks: [0_0]
	current standby tasks: []
	previous active tasks: []

2018-02-08 16:44:16,427 [huipai__exchangeRsteHistory-9d8fb385-20eb-41ab-a8f4-5c33410e3907-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-9d8fb385-20eb-41ab-a8f4-5c33410e3907-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING.
2018-02-08 16:44:16,427 [huipai__exchangeRsteHistory-9d8fb385-20eb-41ab-a8f4-5c33410e3907-StreamThread-1] INFO  [org.apache.kafka.streams.KafkaStreams] - stream-client [huipai__exchangeRsteHistory-9d8fb385-20eb-41ab-a8f4-5c33410e3907] State transition from REBALANCING to RUNNING.
2018-02-08 16:44:16,627 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Successfully joined group spider002 with generation 64
2018-02-08 16:44:16,627 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Setting newly assigned partitions [output-stream-0] for group spider002
2018-02-08 16:46:57,083 [pool-3-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.util.PropertyReaderUtil] - 配置文件被修改
2018-02-08 16:46:57,212 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.util.ESTools] - ESTools开始创建client
2018-02-08 16:46:57,252 [pool-1-thread-1] INFO  [org.elasticsearch.plugins] - [Mastermind] modules [], plugins [], sites []
2018-02-08 16:46:57,275 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Mastermind] creating thread_pool [force_merge], type [fixed], size [1], queue_size [null]
2018-02-08 16:46:57,291 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Mastermind] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
2018-02-08 16:46:57,302 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Mastermind] creating thread_pool [fetch_shard_started], type [scaling], min [1], size [8], keep_alive [5m]
2018-02-08 16:46:57,303 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Mastermind] creating thread_pool [listener], type [fixed], size [2], queue_size [null]
2018-02-08 16:46:57,303 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Mastermind] creating thread_pool [index], type [fixed], size [4], queue_size [200]
2018-02-08 16:46:57,304 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Mastermind] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
2018-02-08 16:46:57,304 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Mastermind] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
2018-02-08 16:46:57,304 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Mastermind] creating thread_pool [generic], type [cached], keep_alive [30s]
2018-02-08 16:46:57,306 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Mastermind] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
2018-02-08 16:46:57,306 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Mastermind] creating thread_pool [search], type [fixed], size [7], queue_size [1k]
2018-02-08 16:46:57,307 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Mastermind] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
2018-02-08 16:46:57,307 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Mastermind] creating thread_pool [fetch_shard_store], type [scaling], min [1], size [8], keep_alive [5m]
2018-02-08 16:46:57,307 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Mastermind] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
2018-02-08 16:46:57,307 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Mastermind] creating thread_pool [get], type [fixed], size [4], queue_size [1k]
2018-02-08 16:46:57,307 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Mastermind] creating thread_pool [bulk], type [fixed], size [4], queue_size [50]
2018-02-08 16:46:57,307 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Mastermind] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
2018-02-08 16:46:57,830 [pool-1-thread-1] DEBUG [org.elasticsearch.common.network] - configuration:

lo
        Software Loopback Interface 1
        inet 127.0.0.1 netmask:255.0.0.0 broadcast:127.255.255.255 scope:host
        inet6 ::1 prefixlen:128 scope:host
        UP MULTICAST LOOPBACK mtu:-1 index:1

eth0
        Realtek PCIe GBE Family Controller
        inet 172.16.73.125 netmask:255.255.255.0 broadcast:172.16.73.255 scope:site
        inet6 fe80::52b:2670:705d:338e prefixlen:64 scope:link
        hardware 1C:1B:0D:B1:E1:B3
        UP MULTICAST mtu:1500 index:2

eth1
        Microsoft Kernel Debug Network Adapter
        MULTICAST mtu:-1 index:3

eth2
        Realtek PCIe GBE Family Controller #2
        MULTICAST mtu:-1 index:4

eth3
        Realtek PCIe GBE Family Controller-WFP Native MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:5

eth4
        Realtek PCIe GBE Family Controller-iNode LightWeight Filter-0000
        MULTICAST mtu:-1 index:6

eth5
        Realtek PCIe GBE Family Controller-QoS Packet Scheduler-0000
        MULTICAST mtu:-1 index:7

eth6
        Realtek PCIe GBE Family Controller-WFP 802.3 MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:8

net0
        WAN Miniport (SSTP)
        MULTICAST mtu:-1 index:9

net1
        WAN Miniport (IKEv2)
        MULTICAST mtu:-1 index:10

net2
        WAN Miniport (L2TP)
        MULTICAST mtu:-1 index:11

net3
        WAN Miniport (PPTP)
        MULTICAST mtu:-1 index:12

ppp0
        WAN Miniport (PPPOE)
        MULTICAST mtu:-1 index:13

eth7
        WAN Miniport (IP)
        MULTICAST mtu:-1 index:14

eth8
        WAN Miniport (IP)-WFP Native MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:15

eth9
        WAN Miniport (IP)-iNode LightWeight Filter-0000
        MULTICAST mtu:-1 index:16

eth10
        WAN Miniport (IP)-QoS Packet Scheduler-0000
        MULTICAST mtu:-1 index:17

eth11
        WAN Miniport (IPv6)
        MULTICAST mtu:-1 index:18

eth12
        WAN Miniport (IPv6)-WFP Native MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:19

eth13
        WAN Miniport (IPv6)-iNode LightWeight Filter-0000
        MULTICAST mtu:-1 index:20

eth14
        WAN Miniport (IPv6)-QoS Packet Scheduler-0000
        MULTICAST mtu:-1 index:21

eth15
        WAN Miniport (Network Monitor)
        MULTICAST mtu:-1 index:22

eth16
        WAN Miniport (Network Monitor)-WFP Native MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:23

eth17
        WAN Miniport (Network Monitor)-iNode LightWeight Filter-0000
        MULTICAST mtu:-1 index:24

eth18
        WAN Miniport (Network Monitor)-QoS Packet Scheduler-0000
        MULTICAST mtu:-1 index:25

net4
        Teredo Tunneling Pseudo-Interface
        inet6 2001:0:9d38:6ab8:28ec:1162:53ef:b682 prefixlen:0
        inet6 fe80::28ec:1162:53ef:b682 prefixlen:32 scope:link
        hardware 00:00:00:00:00:00:00:E0
        UP POINTOPOINT mtu:1280 index:26

2018-02-08 16:46:57,858 [pool-1-thread-1] DEBUG [org.elasticsearch.common.netty] - using gathering [true]
2018-02-08 16:46:57,884 [pool-1-thread-1] DEBUG [org.elasticsearch.client.transport] - [Mastermind] node_sampler_interval[5s]
2018-02-08 16:46:57,900 [pool-1-thread-1] DEBUG [org.elasticsearch.netty.channel.socket.nio.SelectorUtil] - Using select timeout of 500
2018-02-08 16:46:57,901 [pool-1-thread-1] DEBUG [org.elasticsearch.netty.channel.socket.nio.SelectorUtil] - Epoll-bug workaround enabled = false
2018-02-08 16:46:57,930 [pool-1-thread-1] DEBUG [org.elasticsearch.client.transport] - [Mastermind] adding address [{#transport#-1}{172.16.23.13}{172.16.23.13:9303}]
2018-02-08 16:46:57,951 [elasticsearch[Mastermind][management][T#1]] DEBUG [org.elasticsearch.transport.netty] - [Mastermind] connected to node [{#transport#-1}{172.16.23.13}{172.16.23.13:9303}]
2018-02-08 16:46:58,051 [pool-1-thread-1] DEBUG [org.elasticsearch.transport.netty] - [Mastermind] connected to node [{node02}{phQmsLojTs2ghLCQ4Qd9mg}{172.16.23.15}{172.16.23.15:9303}{max_local_storage_nodes=2, master=false}]
2018-02-08 16:46:58,056 [pool-1-thread-1] DEBUG [org.elasticsearch.transport.netty] - [Mastermind] connected to node [{node03}{tRpjIa0lS5-awR_CJldlkw}{172.16.23.15}{172.16.23.15:9302}{max_local_storage_nodes=2, master=true}]
2018-02-08 16:46:58,060 [pool-1-thread-1] DEBUG [org.elasticsearch.transport.netty] - [Mastermind] connected to node [{node01}{QWrvvVLrT8Wlg-yr48Hu8Q}{172.16.23.13}{172.16.23.13:9303}{max_local_storage_nodes=2, master=true}]
2018-02-08 16:46:58,064 [pool-1-thread-1] DEBUG [org.elasticsearch.transport.netty] - [Mastermind] connected to node [{node04}{5UFptUtFQ0iV4_YH_wXgWQ}{172.16.23.16}{172.16.23.16:9303}{max_local_storage_nodes=2, master=true}]
2018-02-08 16:46:58,065 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.util.ESTools] - ESTools创建Elasticsearch Client 结束
2018-02-08 16:46:58,084 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.ConsumerConfig] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [172.16.10.211:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = spider002
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-02-08 16:46:58,149 [pool-1-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.11.0.1
2018-02-08 16:46:58,149 [pool-1-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : c2a0d5f9b1f45bf5
2018-02-08 16:46:58,225 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Discovered coordinator 172.16.10.211:9092 (id: 2147483647 rack: null) for group spider002.
2018-02-08 16:46:58,227 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Revoking previously assigned partitions [] for group spider002
2018-02-08 16:46:58,227 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - (Re-)joining group spider002
2018-02-08 16:46:58,240 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Successfully joined group spider002 with generation 66
2018-02-08 16:46:58,270 [pool-3-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyTopology] - topicConfig.yml
2018-02-08 16:46:58,270 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Setting newly assigned partitions [output-stream-0] for group spider002
2018-02-08 16:46:58,277 [pool-3-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyTopology] - 创建拓扑成功doNot
2018-02-08 16:46:58,280 [pool-3-thread-1] INFO  [org.apache.kafka.streams.StreamsConfig] - StreamsConfig values: 
	application.id = huipai__exchangeRsteHistory
	application.server = 
	bootstrap.servers = [172.16.10.211:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = 
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	default.timestamp.extractor = class org.apache.kafka.streams.processor.WallclockTimestampExtractor
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	key.serde = null
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	timestamp.extractor = null
	value.serde = null
	windowstore.changelog.additional.retention.ms = 86400000
	zookeeper.connect = 

2018-02-08 16:46:58,291 [pool-3-thread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-b7da486d-3f32-4abe-990a-b7e4f9e6aaf6-StreamThread-1] Creating consumer client
2018-02-08 16:46:58,292 [pool-3-thread-1] INFO  [org.apache.kafka.clients.consumer.ConsumerConfig] - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [172.16.10.211:9092]
	check.crcs = true
	client.id = huipai__exchangeRsteHistory-b7da486d-3f32-4abe-990a-b7e4f9e6aaf6-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = huipai__exchangeRsteHistory
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-02-08 16:46:58,300 [pool-3-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.11.0.1
2018-02-08 16:46:58,300 [pool-3-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : c2a0d5f9b1f45bf5
2018-02-08 16:46:58,300 [pool-3-thread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-b7da486d-3f32-4abe-990a-b7e4f9e6aaf6-StreamThread-1] Creating restore consumer client
2018-02-08 16:46:58,300 [pool-3-thread-1] INFO  [org.apache.kafka.clients.consumer.ConsumerConfig] - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [172.16.10.211:9092]
	check.crcs = true
	client.id = huipai__exchangeRsteHistory-b7da486d-3f32-4abe-990a-b7e4f9e6aaf6-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-02-08 16:46:58,303 [pool-3-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.11.0.1
2018-02-08 16:46:58,303 [pool-3-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : c2a0d5f9b1f45bf5
2018-02-08 16:46:58,362 [huipai__exchangeRsteHistory-b7da486d-3f32-4abe-990a-b7e4f9e6aaf6-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-b7da486d-3f32-4abe-990a-b7e4f9e6aaf6-StreamThread-1] Starting
2018-02-08 16:46:58,362 [huipai__exchangeRsteHistory-b7da486d-3f32-4abe-990a-b7e4f9e6aaf6-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-b7da486d-3f32-4abe-990a-b7e4f9e6aaf6-StreamThread-1] State transition from CREATED to RUNNING.
2018-02-08 16:46:58,362 [pool-3-thread-1] INFO  [org.apache.kafka.streams.KafkaStreams] - stream-client [huipai__exchangeRsteHistory-b7da486d-3f32-4abe-990a-b7e4f9e6aaf6] Started Kafka Stream process
2018-02-08 16:46:58,363 [pool-3-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.Application] - 开启流拓扑
2018-02-08 16:46:58,368 [huipai__exchangeRsteHistory-b7da486d-3f32-4abe-990a-b7e4f9e6aaf6-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Discovered coordinator 172.16.10.211:9092 (id: 2147483647 rack: null) for group huipai__exchangeRsteHistory.
2018-02-08 16:46:58,382 [huipai__exchangeRsteHistory-b7da486d-3f32-4abe-990a-b7e4f9e6aaf6-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Revoking previously assigned partitions [] for group huipai__exchangeRsteHistory
2018-02-08 16:46:58,382 [huipai__exchangeRsteHistory-b7da486d-3f32-4abe-990a-b7e4f9e6aaf6-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-b7da486d-3f32-4abe-990a-b7e4f9e6aaf6-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED.
2018-02-08 16:46:58,382 [huipai__exchangeRsteHistory-b7da486d-3f32-4abe-990a-b7e4f9e6aaf6-StreamThread-1] INFO  [org.apache.kafka.streams.KafkaStreams] - stream-client [huipai__exchangeRsteHistory-b7da486d-3f32-4abe-990a-b7e4f9e6aaf6] State transition from RUNNING to REBALANCING.
2018-02-08 16:46:58,382 [huipai__exchangeRsteHistory-b7da486d-3f32-4abe-990a-b7e4f9e6aaf6-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-b7da486d-3f32-4abe-990a-b7e4f9e6aaf6-StreamThread-1] partition revocation took 0 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-02-08 16:46:58,383 [huipai__exchangeRsteHistory-b7da486d-3f32-4abe-990a-b7e4f9e6aaf6-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - (Re-)joining group huipai__exchangeRsteHistory
2018-02-08 16:46:58,392 [huipai__exchangeRsteHistory-b7da486d-3f32-4abe-990a-b7e4f9e6aaf6-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamPartitionAssignor] - stream-thread [huipai__exchangeRsteHistory-b7da486d-3f32-4abe-990a-b7e4f9e6aaf6-StreamThread-1] Assigned tasks to clients as {b7da486d-3f32-4abe-990a-b7e4f9e6aaf6=[activeTasks: ([0_0]) standbyTasks: ([]) assignedTasks: ([0_0]) prevActiveTasks: ([]) prevAssignedTasks: ([0_0]) capacity: 1]}.
2018-02-08 16:46:58,394 [huipai__exchangeRsteHistory-b7da486d-3f32-4abe-990a-b7e4f9e6aaf6-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Successfully joined group huipai__exchangeRsteHistory with generation 42
2018-02-08 16:46:58,395 [huipai__exchangeRsteHistory-b7da486d-3f32-4abe-990a-b7e4f9e6aaf6-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Setting newly assigned partitions [huipai__exchangeRsteHistory-0] for group huipai__exchangeRsteHistory
2018-02-08 16:46:58,395 [huipai__exchangeRsteHistory-b7da486d-3f32-4abe-990a-b7e4f9e6aaf6-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-b7da486d-3f32-4abe-990a-b7e4f9e6aaf6-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED.
2018-02-08 16:46:58,395 [huipai__exchangeRsteHistory-b7da486d-3f32-4abe-990a-b7e4f9e6aaf6-StreamThread-1] INFO  [org.apache.kafka.streams.KafkaStreams] - stream-client [huipai__exchangeRsteHistory-b7da486d-3f32-4abe-990a-b7e4f9e6aaf6] State transition from REBALANCING to REBALANCING.
2018-02-08 16:46:58,401 [huipai__exchangeRsteHistory-b7da486d-3f32-4abe-990a-b7e4f9e6aaf6-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-b7da486d-3f32-4abe-990a-b7e4f9e6aaf6-StreamThread-1] Creating shared producer client
2018-02-08 16:46:58,404 [huipai__exchangeRsteHistory-b7da486d-3f32-4abe-990a-b7e4f9e6aaf6-StreamThread-1] INFO  [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [172.16.10.211:9092]
	buffer.memory = 33554432
	client.id = huipai__exchangeRsteHistory-b7da486d-3f32-4abe-990a-b7e4f9e6aaf6-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-02-08 16:46:58,425 [huipai__exchangeRsteHistory-b7da486d-3f32-4abe-990a-b7e4f9e6aaf6-StreamThread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.11.0.1
2018-02-08 16:46:58,425 [huipai__exchangeRsteHistory-b7da486d-3f32-4abe-990a-b7e4f9e6aaf6-StreamThread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : c2a0d5f9b1f45bf5
2018-02-08 16:46:58,444 [huipai__exchangeRsteHistory-b7da486d-3f32-4abe-990a-b7e4f9e6aaf6-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-b7da486d-3f32-4abe-990a-b7e4f9e6aaf6-StreamThread-1] partition assignment took 49 ms.
	current active tasks: [0_0]
	current standby tasks: []
	previous active tasks: []

2018-02-08 16:46:58,465 [huipai__exchangeRsteHistory-b7da486d-3f32-4abe-990a-b7e4f9e6aaf6-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-b7da486d-3f32-4abe-990a-b7e4f9e6aaf6-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING.
2018-02-08 16:46:58,465 [huipai__exchangeRsteHistory-b7da486d-3f32-4abe-990a-b7e4f9e6aaf6-StreamThread-1] INFO  [org.apache.kafka.streams.KafkaStreams] - stream-client [huipai__exchangeRsteHistory-b7da486d-3f32-4abe-990a-b7e4f9e6aaf6] State transition from REBALANCING to RUNNING.
2018-02-08 17:16:41,870 [pool-3-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.util.PropertyReaderUtil] - 配置文件被修改
2018-02-08 17:16:41,995 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.util.ESTools] - ESTools开始创建client
2018-02-08 17:16:42,035 [pool-1-thread-1] INFO  [org.elasticsearch.plugins] - [Bella Donna] modules [], plugins [], sites []
2018-02-08 17:16:42,050 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Bella Donna] creating thread_pool [force_merge], type [fixed], size [1], queue_size [null]
2018-02-08 17:16:42,057 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Bella Donna] creating thread_pool [percolate], type [fixed], size [4], queue_size [1k]
2018-02-08 17:16:42,069 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Bella Donna] creating thread_pool [fetch_shard_started], type [scaling], min [1], size [8], keep_alive [5m]
2018-02-08 17:16:42,070 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Bella Donna] creating thread_pool [listener], type [fixed], size [2], queue_size [null]
2018-02-08 17:16:42,070 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Bella Donna] creating thread_pool [index], type [fixed], size [4], queue_size [200]
2018-02-08 17:16:42,070 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Bella Donna] creating thread_pool [refresh], type [scaling], min [1], size [2], keep_alive [5m]
2018-02-08 17:16:42,071 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Bella Donna] creating thread_pool [suggest], type [fixed], size [4], queue_size [1k]
2018-02-08 17:16:42,071 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Bella Donna] creating thread_pool [generic], type [cached], keep_alive [30s]
2018-02-08 17:16:42,071 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Bella Donna] creating thread_pool [warmer], type [scaling], min [1], size [2], keep_alive [5m]
2018-02-08 17:16:42,072 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Bella Donna] creating thread_pool [search], type [fixed], size [7], queue_size [1k]
2018-02-08 17:16:42,073 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Bella Donna] creating thread_pool [flush], type [scaling], min [1], size [2], keep_alive [5m]
2018-02-08 17:16:42,073 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Bella Donna] creating thread_pool [fetch_shard_store], type [scaling], min [1], size [8], keep_alive [5m]
2018-02-08 17:16:42,073 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Bella Donna] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
2018-02-08 17:16:42,073 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Bella Donna] creating thread_pool [get], type [fixed], size [4], queue_size [1k]
2018-02-08 17:16:42,074 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Bella Donna] creating thread_pool [bulk], type [fixed], size [4], queue_size [50]
2018-02-08 17:16:42,074 [pool-1-thread-1] DEBUG [org.elasticsearch.threadpool] - [Bella Donna] creating thread_pool [snapshot], type [scaling], min [1], size [2], keep_alive [5m]
2018-02-08 17:16:42,711 [pool-1-thread-1] DEBUG [org.elasticsearch.common.network] - configuration:

lo
        Software Loopback Interface 1
        inet 127.0.0.1 netmask:255.0.0.0 broadcast:127.255.255.255 scope:host
        inet6 ::1 prefixlen:128 scope:host
        UP MULTICAST LOOPBACK mtu:-1 index:1

eth0
        Realtek PCIe GBE Family Controller
        inet 172.16.73.125 netmask:255.255.255.0 broadcast:172.16.73.255 scope:site
        inet6 fe80::52b:2670:705d:338e prefixlen:64 scope:link
        hardware 1C:1B:0D:B1:E1:B3
        UP MULTICAST mtu:1500 index:2

eth1
        Microsoft Kernel Debug Network Adapter
        MULTICAST mtu:-1 index:3

eth2
        Realtek PCIe GBE Family Controller #2
        MULTICAST mtu:-1 index:4

eth3
        Realtek PCIe GBE Family Controller-WFP Native MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:5

eth4
        Realtek PCIe GBE Family Controller-iNode LightWeight Filter-0000
        MULTICAST mtu:-1 index:6

eth5
        Realtek PCIe GBE Family Controller-QoS Packet Scheduler-0000
        MULTICAST mtu:-1 index:7

eth6
        Realtek PCIe GBE Family Controller-WFP 802.3 MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:8

net0
        WAN Miniport (SSTP)
        MULTICAST mtu:-1 index:9

net1
        WAN Miniport (IKEv2)
        MULTICAST mtu:-1 index:10

net2
        WAN Miniport (L2TP)
        MULTICAST mtu:-1 index:11

net3
        WAN Miniport (PPTP)
        MULTICAST mtu:-1 index:12

ppp0
        WAN Miniport (PPPOE)
        MULTICAST mtu:-1 index:13

eth7
        WAN Miniport (IP)
        MULTICAST mtu:-1 index:14

eth8
        WAN Miniport (IP)-WFP Native MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:15

eth9
        WAN Miniport (IP)-iNode LightWeight Filter-0000
        MULTICAST mtu:-1 index:16

eth10
        WAN Miniport (IP)-QoS Packet Scheduler-0000
        MULTICAST mtu:-1 index:17

eth11
        WAN Miniport (IPv6)
        MULTICAST mtu:-1 index:18

eth12
        WAN Miniport (IPv6)-WFP Native MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:19

eth13
        WAN Miniport (IPv6)-iNode LightWeight Filter-0000
        MULTICAST mtu:-1 index:20

eth14
        WAN Miniport (IPv6)-QoS Packet Scheduler-0000
        MULTICAST mtu:-1 index:21

eth15
        WAN Miniport (Network Monitor)
        MULTICAST mtu:-1 index:22

eth16
        WAN Miniport (Network Monitor)-WFP Native MAC Layer LightWeight Filter-0000
        MULTICAST mtu:-1 index:23

eth17
        WAN Miniport (Network Monitor)-iNode LightWeight Filter-0000
        MULTICAST mtu:-1 index:24

eth18
        WAN Miniport (Network Monitor)-QoS Packet Scheduler-0000
        MULTICAST mtu:-1 index:25

net4
        Teredo Tunneling Pseudo-Interface
        inet6 2001:0:9d38:6ab8:28ec:1162:53ef:b682 prefixlen:0
        inet6 fe80::28ec:1162:53ef:b682 prefixlen:32 scope:link
        hardware 00:00:00:00:00:00:00:E0
        UP POINTOPOINT mtu:1280 index:26

2018-02-08 17:16:42,735 [pool-1-thread-1] DEBUG [org.elasticsearch.common.netty] - using gathering [true]
2018-02-08 17:16:42,757 [pool-1-thread-1] DEBUG [org.elasticsearch.client.transport] - [Bella Donna] node_sampler_interval[5s]
2018-02-08 17:16:42,771 [pool-1-thread-1] DEBUG [org.elasticsearch.netty.channel.socket.nio.SelectorUtil] - Using select timeout of 500
2018-02-08 17:16:42,771 [pool-1-thread-1] DEBUG [org.elasticsearch.netty.channel.socket.nio.SelectorUtil] - Epoll-bug workaround enabled = false
2018-02-08 17:16:42,801 [pool-1-thread-1] DEBUG [org.elasticsearch.client.transport] - [Bella Donna] adding address [{#transport#-1}{172.16.23.13}{172.16.23.13:9303}]
2018-02-08 17:16:42,820 [elasticsearch[Bella Donna][management][T#1]] DEBUG [org.elasticsearch.transport.netty] - [Bella Donna] connected to node [{#transport#-1}{172.16.23.13}{172.16.23.13:9303}]
2018-02-08 17:16:42,925 [pool-1-thread-1] DEBUG [org.elasticsearch.transport.netty] - [Bella Donna] connected to node [{node02}{phQmsLojTs2ghLCQ4Qd9mg}{172.16.23.15}{172.16.23.15:9303}{max_local_storage_nodes=2, master=false}]
2018-02-08 17:16:42,930 [pool-1-thread-1] DEBUG [org.elasticsearch.transport.netty] - [Bella Donna] connected to node [{node03}{tRpjIa0lS5-awR_CJldlkw}{172.16.23.15}{172.16.23.15:9302}{max_local_storage_nodes=2, master=true}]
2018-02-08 17:16:42,936 [pool-1-thread-1] DEBUG [org.elasticsearch.transport.netty] - [Bella Donna] connected to node [{node04}{5UFptUtFQ0iV4_YH_wXgWQ}{172.16.23.16}{172.16.23.16:9303}{max_local_storage_nodes=2, master=true}]
2018-02-08 17:16:42,939 [pool-1-thread-1] DEBUG [org.elasticsearch.transport.netty] - [Bella Donna] connected to node [{node01}{QWrvvVLrT8Wlg-yr48Hu8Q}{172.16.23.13}{172.16.23.13:9303}{max_local_storage_nodes=2, master=true}]
2018-02-08 17:16:42,940 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.util.ESTools] - ESTools创建Elasticsearch Client 结束
2018-02-08 17:16:42,958 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.ConsumerConfig] - ConsumerConfig values: 
	auto.commit.interval.ms = 1000
	auto.offset.reset = earliest
	bootstrap.servers = [172.16.10.211:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = spider002
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2018-02-08 17:16:43,021 [pool-1-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.11.0.1
2018-02-08 17:16:43,021 [pool-1-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : c2a0d5f9b1f45bf5
2018-02-08 17:16:43,099 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Discovered coordinator 172.16.10.211:9092 (id: 2147483647 rack: null) for group spider002.
2018-02-08 17:16:43,101 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Revoking previously assigned partitions [] for group spider002
2018-02-08 17:16:43,101 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - (Re-)joining group spider002
2018-02-08 17:16:43,111 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Successfully joined group spider002 with generation 68
2018-02-08 17:16:43,142 [pool-1-thread-1] INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Setting newly assigned partitions [output-stream-0] for group spider002
2018-02-08 17:16:43,144 [pool-3-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyTopology] - topicConfig.yml
2018-02-08 17:16:43,151 [pool-3-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyTopology] - 创建拓扑成功doNot
2018-02-08 17:16:43,156 [pool-3-thread-1] INFO  [org.apache.kafka.streams.StreamsConfig] - StreamsConfig values: 
	application.id = huipai__exchangeRsteHistory
	application.server = 
	bootstrap.servers = [172.16.10.211:9092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = 
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	default.timestamp.extractor = class org.apache.kafka.streams.processor.WallclockTimestampExtractor
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$StringSerde
	key.serde = null
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 1
	request.timeout.ms = 40000
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	timestamp.extractor = null
	value.serde = null
	windowstore.changelog.additional.retention.ms = 86400000
	zookeeper.connect = 

2018-02-08 17:16:43,166 [pool-3-thread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-3f85ccb2-56be-42ce-ae0d-fc4db3ae967d-StreamThread-1] Creating consumer client
2018-02-08 17:16:43,180 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,180 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,181 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,182 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,182 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,183 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,183 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,183 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,183 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,183 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,184 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,184 [pool-3-thread-1] INFO  [org.apache.kafka.clients.consumer.ConsumerConfig] - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [172.16.10.211:9092]
	check.crcs = true
	client.id = huipai__exchangeRsteHistory-3f85ccb2-56be-42ce-ae0d-fc4db3ae967d-StreamThread-1-consumer
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = huipai__exchangeRsteHistory
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-02-08 17:16:43,184 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,184 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,184 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,184 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,184 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,185 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,185 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,185 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,185 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,185 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,185 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,186 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,186 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,186 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,186 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,186 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,186 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,186 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,187 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,187 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,187 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,187 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,187 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,187 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,187 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,188 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,188 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,188 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,188 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,188 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,189 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,193 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,193 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,193 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,193 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,193 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,193 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,194 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,194 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,194 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,194 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,194 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,194 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,194 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,195 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,195 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,195 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,195 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,195 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,195 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,195 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,195 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,196 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,196 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,196 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,196 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,196 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,196 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,196 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,196 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,197 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,197 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,197 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,197 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,197 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,197 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,199 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,199 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,199 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,199 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,199 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,200 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,200 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,204 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,205 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,206 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,206 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,206 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,208 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,208 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,208 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,208 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,208 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,209 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,209 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,209 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,209 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,209 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,209 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,209 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,209 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,209 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,209 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,209 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,209 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,209 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,210 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,210 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,210 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,210 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,210 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,210 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,210 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,210 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,210 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,210 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,211 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,211 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,211 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,211 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,211 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,211 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,212 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,212 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,212 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,212 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,213 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,213 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,213 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,213 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,213 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,213 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,213 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,213 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,214 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,214 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,214 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,214 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,214 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,214 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,214 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,214 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,214 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,214 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,214 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,214 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,214 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,214 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,214 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,214 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,215 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,215 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,215 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,215 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,215 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,217 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,217 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,217 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,217 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,217 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,217 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,217 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,218 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,218 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,218 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,218 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,218 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,218 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,218 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,218 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,218 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,218 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,218 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,218 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,218 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,220 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,220 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,220 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,220 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,220 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,221 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,221 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,221 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,221 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,221 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,221 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,222 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,222 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,222 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,222 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,222 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,222 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,222 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,223 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,223 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,223 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,223 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,223 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,223 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,223 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,224 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,224 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,224 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,224 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,224 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,224 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,224 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,224 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,224 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,192 [pool-3-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.11.0.1
2018-02-08 17:16:43,225 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,225 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,225 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,226 [pool-3-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : c2a0d5f9b1f45bf5
2018-02-08 17:16:43,226 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,226 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,226 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,226 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,226 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,226 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,226 [pool-3-thread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-3f85ccb2-56be-42ce-ae0d-fc4db3ae967d-StreamThread-1] Creating restore consumer client
2018-02-08 17:16:43,226 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,226 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,226 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,226 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,226 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,227 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,227 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,227 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,227 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,227 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,227 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,227 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,227 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,228 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,228 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,228 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,228 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,228 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,228 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,228 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,228 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,228 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,228 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,230 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,230 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,231 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,231 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,231 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,231 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,231 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,231 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,231 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,231 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,231 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,231 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,231 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,231 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,231 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,231 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,231 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,231 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,231 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,231 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,232 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,232 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,232 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,232 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,232 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,232 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,232 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,227 [pool-3-thread-1] INFO  [org.apache.kafka.clients.consumer.ConsumerConfig] - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [172.16.10.211:9092]
	check.crcs = true
	client.id = huipai__exchangeRsteHistory-3f85ccb2-56be-42ce-ae0d-fc4db3ae967d-StreamThread-1-restore-consumer
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 2147483647
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2018-02-08 17:16:43,232 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,232 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,232 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,232 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,232 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,232 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,232 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,232 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,232 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,232 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,232 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,233 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,233 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,233 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,233 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,233 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,233 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,233 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,233 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,233 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,233 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,233 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,233 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,233 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,233 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,233 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,233 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,233 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,233 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,233 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,233 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,233 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,233 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,234 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,234 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,234 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,234 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,234 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,234 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,234 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,234 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,234 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,234 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,234 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,234 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,234 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,234 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,234 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,234 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,234 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,234 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,234 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,234 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,234 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,234 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,235 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,235 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,235 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,235 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,235 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,235 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,235 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,235 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,235 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,235 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,235 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,235 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,235 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,235 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,235 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,235 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,235 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,235 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,237 [pool-3-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.11.0.1
2018-02-08 17:16:43,237 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,237 [pool-3-thread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : c2a0d5f9b1f45bf5
2018-02-08 17:16:43,237 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,237 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,237 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,237 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,237 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,237 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,237 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,237 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,237 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,237 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,237 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,237 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,237 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,237 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,238 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,238 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,238 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,238 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,238 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,238 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,238 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,238 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,238 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,238 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,238 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,238 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,238 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,238 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,238 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,238 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,238 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,238 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,238 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,238 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,239 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,239 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,239 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,239 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,239 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,239 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,239 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,239 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,239 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,239 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,239 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,239 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,239 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,239 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,239 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,239 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,239 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,239 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,239 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,239 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,239 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,240 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,240 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,240 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,240 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,240 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,240 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,240 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,240 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,240 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,240 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,240 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,240 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,240 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,240 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,240 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,240 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,240 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,240 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,240 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,240 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,240 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,240 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,240 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,241 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,241 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,241 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,241 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,241 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,241 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,241 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,241 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,241 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,241 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,241 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,241 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,241 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,241 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,241 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,241 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,241 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,241 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,241 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,241 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,241 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,241 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,241 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,241 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,241 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,242 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,242 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,242 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,242 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,242 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,242 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,242 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,242 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,242 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,242 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,242 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,242 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,242 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,242 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,242 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,242 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,242 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,242 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,242 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,242 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,242 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,242 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,242 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,242 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,243 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,243 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,243 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,243 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,243 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,243 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,243 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,243 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,243 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,243 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,243 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,244 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,244 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,244 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,244 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,244 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,244 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,244 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,245 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,245 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,245 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,245 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,245 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,245 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,245 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,245 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,245 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,245 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,245 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,245 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,279 [pool-1-thread-1] DEBUG [org.elasticsearch.common.compress.lzf] - using decoder[VanillaChunkDecoder] 
2018-02-08 17:16:43,308 [huipai__exchangeRsteHistory-3f85ccb2-56be-42ce-ae0d-fc4db3ae967d-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-3f85ccb2-56be-42ce-ae0d-fc4db3ae967d-StreamThread-1] Starting
2018-02-08 17:16:43,308 [huipai__exchangeRsteHistory-3f85ccb2-56be-42ce-ae0d-fc4db3ae967d-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-3f85ccb2-56be-42ce-ae0d-fc4db3ae967d-StreamThread-1] State transition from CREATED to RUNNING.
2018-02-08 17:16:43,308 [pool-3-thread-1] INFO  [org.apache.kafka.streams.KafkaStreams] - stream-client [huipai__exchangeRsteHistory-3f85ccb2-56be-42ce-ae0d-fc4db3ae967d] Started Kafka Stream process
2018-02-08 17:16:43,308 [pool-3-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.Application] - 开启流拓扑
2018-02-08 17:16:43,327 [huipai__exchangeRsteHistory-3f85ccb2-56be-42ce-ae0d-fc4db3ae967d-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Discovered coordinator 172.16.10.211:9092 (id: 2147483647 rack: null) for group huipai__exchangeRsteHistory.
2018-02-08 17:16:43,328 [huipai__exchangeRsteHistory-3f85ccb2-56be-42ce-ae0d-fc4db3ae967d-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Revoking previously assigned partitions [] for group huipai__exchangeRsteHistory
2018-02-08 17:16:43,328 [huipai__exchangeRsteHistory-3f85ccb2-56be-42ce-ae0d-fc4db3ae967d-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-3f85ccb2-56be-42ce-ae0d-fc4db3ae967d-StreamThread-1] State transition from RUNNING to PARTITIONS_REVOKED.
2018-02-08 17:16:43,328 [huipai__exchangeRsteHistory-3f85ccb2-56be-42ce-ae0d-fc4db3ae967d-StreamThread-1] INFO  [org.apache.kafka.streams.KafkaStreams] - stream-client [huipai__exchangeRsteHistory-3f85ccb2-56be-42ce-ae0d-fc4db3ae967d] State transition from RUNNING to REBALANCING.
2018-02-08 17:16:43,329 [huipai__exchangeRsteHistory-3f85ccb2-56be-42ce-ae0d-fc4db3ae967d-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-3f85ccb2-56be-42ce-ae0d-fc4db3ae967d-StreamThread-1] partition revocation took 1 ms.
	suspended active tasks: []
	suspended standby tasks: []
2018-02-08 17:16:43,329 [huipai__exchangeRsteHistory-3f85ccb2-56be-42ce-ae0d-fc4db3ae967d-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - (Re-)joining group huipai__exchangeRsteHistory
2018-02-08 17:16:43,339 [huipai__exchangeRsteHistory-3f85ccb2-56be-42ce-ae0d-fc4db3ae967d-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamPartitionAssignor] - stream-thread [huipai__exchangeRsteHistory-3f85ccb2-56be-42ce-ae0d-fc4db3ae967d-StreamThread-1] Assigned tasks to clients as {3f85ccb2-56be-42ce-ae0d-fc4db3ae967d=[activeTasks: ([0_0]) standbyTasks: ([]) assignedTasks: ([0_0]) prevActiveTasks: ([]) prevAssignedTasks: ([0_0]) capacity: 1]}.
2018-02-08 17:16:43,343 [huipai__exchangeRsteHistory-3f85ccb2-56be-42ce-ae0d-fc4db3ae967d-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.AbstractCoordinator] - Successfully joined group huipai__exchangeRsteHistory with generation 44
2018-02-08 17:16:43,344 [huipai__exchangeRsteHistory-3f85ccb2-56be-42ce-ae0d-fc4db3ae967d-StreamThread-1] INFO  [org.apache.kafka.clients.consumer.internals.ConsumerCoordinator] - Setting newly assigned partitions [huipai__exchangeRsteHistory-0] for group huipai__exchangeRsteHistory
2018-02-08 17:16:43,344 [huipai__exchangeRsteHistory-3f85ccb2-56be-42ce-ae0d-fc4db3ae967d-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-3f85ccb2-56be-42ce-ae0d-fc4db3ae967d-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED.
2018-02-08 17:16:43,344 [huipai__exchangeRsteHistory-3f85ccb2-56be-42ce-ae0d-fc4db3ae967d-StreamThread-1] INFO  [org.apache.kafka.streams.KafkaStreams] - stream-client [huipai__exchangeRsteHistory-3f85ccb2-56be-42ce-ae0d-fc4db3ae967d] State transition from REBALANCING to REBALANCING.
2018-02-08 17:16:43,352 [huipai__exchangeRsteHistory-3f85ccb2-56be-42ce-ae0d-fc4db3ae967d-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-3f85ccb2-56be-42ce-ae0d-fc4db3ae967d-StreamThread-1] Creating shared producer client
2018-02-08 17:16:43,357 [huipai__exchangeRsteHistory-3f85ccb2-56be-42ce-ae0d-fc4db3ae967d-StreamThread-1] INFO  [org.apache.kafka.clients.producer.ProducerConfig] - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [172.16.10.211:9092]
	buffer.memory = 33554432
	client.id = huipai__exchangeRsteHistory-3f85ccb2-56be-42ce-ae0d-fc4db3ae967d-StreamThread-1-producer
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 100
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2018-02-08 17:16:43,369 [huipai__exchangeRsteHistory-3f85ccb2-56be-42ce-ae0d-fc4db3ae967d-StreamThread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka version : 0.11.0.1
2018-02-08 17:16:43,370 [huipai__exchangeRsteHistory-3f85ccb2-56be-42ce-ae0d-fc4db3ae967d-StreamThread-1] INFO  [org.apache.kafka.common.utils.AppInfoParser] - Kafka commitId : c2a0d5f9b1f45bf5
2018-02-08 17:16:43,378 [huipai__exchangeRsteHistory-3f85ccb2-56be-42ce-ae0d-fc4db3ae967d-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-3f85ccb2-56be-42ce-ae0d-fc4db3ae967d-StreamThread-1] partition assignment took 34 ms.
	current active tasks: [0_0]
	current standby tasks: []
	previous active tasks: []

2018-02-08 17:16:43,411 [huipai__exchangeRsteHistory-3f85ccb2-56be-42ce-ae0d-fc4db3ae967d-StreamThread-1] INFO  [org.apache.kafka.streams.processor.internals.StreamThread] - stream-thread [huipai__exchangeRsteHistory-3f85ccb2-56be-42ce-ae0d-fc4db3ae967d-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING.
2018-02-08 17:16:43,411 [huipai__exchangeRsteHistory-3f85ccb2-56be-42ce-ae0d-fc4db3ae967d-StreamThread-1] INFO  [org.apache.kafka.streams.KafkaStreams] - stream-client [huipai__exchangeRsteHistory-3f85ccb2-56be-42ce-ae0d-fc4db3ae967d] State transition from REBALANCING to RUNNING.
2018-02-08 17:16:43,667 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 上传数据成功！
2018-02-08 17:16:43,675 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,675 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,675 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,675 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,675 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,675 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,675 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,675 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,675 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,675 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,675 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,675 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,675 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,675 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,675 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,675 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,675 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,675 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,676 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,676 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,676 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,676 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,676 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,676 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,676 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,676 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,676 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,676 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,676 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,676 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,676 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,676 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,676 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,676 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,676 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,676 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,676 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,676 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,676 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,677 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,677 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,677 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,677 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,677 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,677 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,677 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,677 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,677 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,677 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,677 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,677 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,677 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,677 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,677 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,677 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,677 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,677 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,677 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,677 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,677 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,677 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,677 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,677 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,678 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,678 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,678 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,678 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,678 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,678 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,678 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,678 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,678 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,678 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,678 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,678 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,678 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,678 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,678 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,678 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,678 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,678 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,678 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,678 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,678 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,679 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,679 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,679 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,679 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,679 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,679 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,679 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,679 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,679 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,679 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,679 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,679 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,679 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,679 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,679 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,679 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,679 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,679 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,679 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,679 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,679 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,680 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,680 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,680 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,680 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,680 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,680 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,680 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,680 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,680 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,680 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,680 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,680 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,680 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,680 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,680 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,680 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,680 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,680 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,680 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,680 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,680 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,680 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,680 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,680 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,680 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,680 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,680 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,681 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,681 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,681 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,681 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,681 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,681 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,681 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,681 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,681 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,681 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,681 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,681 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,681 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,681 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,681 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,681 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,682 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,682 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,682 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,682 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,682 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,682 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,682 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,682 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,682 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,682 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,682 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,682 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,682 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,683 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,683 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,683 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,683 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,683 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,683 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,683 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,683 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,683 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,683 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,683 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,683 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,683 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,683 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,683 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,683 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,683 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,683 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,683 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,683 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,683 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,683 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,683 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,683 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,683 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,683 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,683 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,683 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,684 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,684 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,684 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,684 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,684 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,684 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,684 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,684 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,684 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,684 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,684 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,684 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,684 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,684 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,684 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,684 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,684 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,684 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,684 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,684 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,684 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,685 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,685 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,685 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,685 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,685 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,685 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,685 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,685 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,685 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,685 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,685 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,685 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,685 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,685 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,685 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,685 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,685 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,685 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,685 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,685 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,685 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,685 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,685 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,685 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,685 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,686 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,686 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,686 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,686 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,686 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,686 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,686 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,686 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,686 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,686 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,686 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,686 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,686 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,686 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,686 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,686 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,686 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,686 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,686 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,686 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,686 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,686 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,686 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,686 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,686 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,686 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,686 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,686 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,687 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,687 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,687 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,687 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,687 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,687 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,687 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,687 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,687 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,687 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,687 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,687 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,687 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,687 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,687 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,687 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,687 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,687 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,687 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,687 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,687 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,687 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,687 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,687 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,687 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,687 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,687 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,687 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,688 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,688 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,688 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,688 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,688 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,688 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,688 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,688 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,688 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,688 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,688 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,688 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,688 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,688 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,688 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,688 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,688 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,688 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,688 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,688 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,688 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,688 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,688 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,688 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,688 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,688 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,688 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,688 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,689 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,689 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,689 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,689 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,689 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,689 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,689 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,689 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,689 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,689 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,689 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,689 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,689 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,689 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,689 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,689 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,689 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,689 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,689 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,689 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,689 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,689 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,689 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,689 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,689 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,690 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,690 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,690 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,690 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,690 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,690 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,690 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,690 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,690 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,690 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,690 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,690 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,690 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,690 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,690 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,690 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,690 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,690 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,690 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,690 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,690 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,690 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,690 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,690 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,690 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,690 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,690 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,691 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,691 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,691 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,691 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,691 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,691 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,691 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,691 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,691 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,691 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,691 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,691 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,691 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,691 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,691 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,691 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,691 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,691 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,691 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,691 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,691 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,691 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,691 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,691 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,691 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,691 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,691 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,692 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,692 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,692 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,692 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,692 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,692 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,692 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,692 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,692 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,692 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,692 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,692 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,692 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,692 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,692 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,692 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,692 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,692 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,692 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,692 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,693 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,693 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,693 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,693 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,693 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,693 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,693 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,693 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,693 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,693 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,693 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,693 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,693 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,693 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,693 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,693 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,693 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,693 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,694 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,694 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,694 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,694 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,694 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,694 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,694 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,694 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,694 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,694 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,694 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,694 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,694 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,694 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,694 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,694 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,694 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,694 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,694 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,694 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,694 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,694 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,694 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,694 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,694 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,694 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,694 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,695 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,695 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,695 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,695 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,695 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,695 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,695 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,695 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,695 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,695 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,695 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,695 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,695 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,695 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,695 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,695 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,695 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,695 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,695 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,695 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,696 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,696 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,696 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,696 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,696 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,696 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,696 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,696 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,696 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,696 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,696 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,696 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,696 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,696 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,696 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,696 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,696 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,942 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 上传数据成功！
2018-02-08 17:16:43,949 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,950 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,950 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,950 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,950 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,950 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,950 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,950 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,950 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,950 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,950 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,950 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,950 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,950 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,950 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,950 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,950 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,950 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,954 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,954 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,954 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,955 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,955 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,955 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,955 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,955 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,955 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,955 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,955 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,955 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,955 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,955 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,955 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,955 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,955 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,955 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,955 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,955 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,955 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,955 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,956 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,956 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,956 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,956 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,956 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,956 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,956 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,956 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,956 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,956 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,956 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,956 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,956 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,956 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,956 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,956 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,956 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,956 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,956 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,956 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,956 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,956 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,956 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,956 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,957 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,957 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,957 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,957 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,957 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,957 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,957 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,957 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,957 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,957 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,957 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,957 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,957 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,957 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,957 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,957 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,957 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,957 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,957 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,957 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,957 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,958 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,958 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,958 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,958 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,958 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,958 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,958 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,958 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,958 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,958 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,958 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,958 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,958 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,958 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,958 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,958 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,958 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,958 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,958 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,958 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,958 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,958 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,958 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,958 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,958 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,958 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,958 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,958 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,958 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,959 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,959 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,959 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,959 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,959 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,959 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,959 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,959 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,959 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,959 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,959 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,959 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,959 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,959 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,959 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,959 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,959 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,959 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,959 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,959 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,959 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,960 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,960 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,960 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,960 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,960 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,960 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,960 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,960 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,960 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,960 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,960 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,960 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,960 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,960 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,960 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,961 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,961 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,961 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,961 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,961 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,961 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,961 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,961 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,961 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,961 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,961 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,961 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,961 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,961 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,961 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,961 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,961 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,961 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,961 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,961 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,961 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,961 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,961 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,962 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,962 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,962 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,962 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,962 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,962 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,962 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,962 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,962 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,962 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,962 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,962 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,962 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,962 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,962 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,962 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,962 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,962 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,962 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,962 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,962 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,962 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,963 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,963 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,963 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,963 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,963 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,963 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,963 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,963 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,963 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,963 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,963 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,963 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,963 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,964 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,964 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,964 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,964 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,964 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,964 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,964 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,965 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,965 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,965 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,965 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,965 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,965 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,965 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,965 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,965 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,965 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,965 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,965 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,965 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,965 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,965 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,965 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,965 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,965 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,965 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,965 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,965 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,965 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,966 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,966 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,966 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,966 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,966 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,966 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,966 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,966 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,966 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,966 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,966 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,966 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,966 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,966 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,966 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,967 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,967 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,967 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,967 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,967 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,967 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,967 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,967 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,967 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,967 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,967 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,967 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,967 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,967 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,967 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,967 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,968 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,968 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,968 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,968 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,968 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,968 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,968 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,968 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,968 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,968 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,968 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,968 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,969 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,969 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,969 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,969 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,969 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,969 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,969 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,969 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,969 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,969 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,969 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,969 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,969 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,969 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,969 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,969 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,969 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,970 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,970 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,970 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,970 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,970 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,970 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,970 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,970 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,970 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,970 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,970 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,970 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,970 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,970 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,970 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,970 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,970 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,970 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,970 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,970 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,970 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,970 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,970 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,970 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,971 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,971 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,971 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,971 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,971 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,971 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,971 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,971 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,971 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,971 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,971 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,971 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,971 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,971 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,971 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,971 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,971 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,971 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,971 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,972 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,972 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,972 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,972 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,972 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,972 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,972 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,972 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,972 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,972 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,972 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,972 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,972 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,972 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,972 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,972 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,972 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,972 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,972 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,972 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,972 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,973 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,973 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,973 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,973 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,973 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,973 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,973 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,973 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,973 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,973 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,973 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,973 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,973 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,973 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,973 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,973 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,973 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,973 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,973 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,973 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,973 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,973 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,973 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,973 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,973 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,974 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,974 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,974 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,974 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,974 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,974 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,974 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,974 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,974 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,974 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,974 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,974 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,974 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,974 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,974 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,974 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,974 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,974 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,974 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,974 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,974 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,974 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,975 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,975 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,975 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,975 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,975 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,975 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,975 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,975 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,975 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,975 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,975 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,975 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,975 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,975 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,975 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,975 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,975 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,975 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,975 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,975 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,975 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,975 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,975 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,975 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,975 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,975 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,976 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,976 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,976 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,976 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,976 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,976 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,976 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,976 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,976 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,976 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,976 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,976 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,976 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,976 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,976 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,976 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,976 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,976 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,976 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,976 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,976 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,976 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,976 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,976 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,976 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,976 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,976 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,976 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,977 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,977 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,977 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,977 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,977 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,977 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,977 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,977 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,977 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,977 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,977 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,977 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,977 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,977 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,977 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,977 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:43,977 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 添加xrs_db,huipai__exchangeRsteHistory成功！
2018-02-08 17:16:44,211 [pool-1-thread-1] INFO  [cn.com.bonc.kafkaDataProcess.kafka.MyKafkaConsumer] - 上传数据成功！
